#Tasks

1/31

    [ ] Comparison Report
        [ ] it's own class
        [ ] load a suite + a benchmark-suite:
        [ ] methods to compare the suites against each other

1/30

    Commit-1
        [x] displaySummaryStats returns str instead of print
            [x] then you can unit test it

        [x] Specific Row Aggregatgors
        [~] Radius Delta Calc e.g. diff from 3-prev-frame-avg

    
    [ ] EvalSuite.fullReport()
        [x] multiple
        [x] custom agg fields, e.g. balls < 20 pixels

    [ ] Need to flow-thru video-notes: 
        e.g. framesize -> impacts "relative" ballsize

    [ ] Need to flow-thru frame-notes: 
        e.g. 'ball-obfusicated'=True -> checkTrackSuccess!=False

    Misc/Thoughts
    
        Really need to fiugure out how to sql-i/o with the pandas into master
        and whether we have enough fine-grained control to do this?
        
        EvalHelpers should be EvalComponents and several of the classes, e.g.
        EvalDataset should be factored out to EvalHelpers

        Ideas for metrics:
            more like PixelConfusionMatrix where we compare each "true" ball pixel
            against whether it was marked
    

1/27
    
    [x] Calc'd fields + Property fields
        [x] can you build series calculations in jupyter?
        [x] merge evalData + evalPropData in jupyter
        [x] refactor repeated code blocks
        [x] add float formatters for DFHelper
        [x] change df names to full evalData df becomes default flow-thru


    [x] Specific Row Aggregatgors
    [ ] Radius Delta Calc e.g. diff from 3-prev-frame-avg
    
    [ ] Multi-Obj-Tracking:
        [ ] separate the baseline-obj-enum from track-obj-enum
        [ ] do it for more than obj-enum=0
        [ ] automatic inference for how many obj's to eval
        [ ] allow ControlTracking to track different obj-enum's
        [ ] flow-thru to all classes

    [ ] Speed Estimate Book

    Also
    [ ] add framenotes to outcome_data
    [ ] have framenotes flow into EvalTracker e.g. ball-obfusicated -> less stringent
        eval metrics.

    Misc
    [ ] displaySummaryStats returns str instead of print
        [ ] then you can unit test it
    [ ] fix checkTrackSuccess metric
    [x] fix propTrackRadius
    [x] add new test data
    [ ] add dependencies in github: PIL, mpltoolkit (Axes3d), IPython (display)

    Ideas
    [ ] for presentation:
        show the challenge of tracking a distance object, a moving object, etc 
        Design-Build-Test: hourglass shape...lots of design and lots of test, limited build

1/26

    Notes
        
        DataModels references:
            EvalTracker -(reference to)-> OutcomeData [to do the Eval]
            OutcomeData.outcomeData (df) -(values)-> DFHelper
            OutcomeData.evalData    (df) -(values)-> DFHelper
            OutcomeData.evalData    (df) -(values)-> AggEval

        Eval Metrics Scope - in what situations do they apply?

            only for inputframes:
                compareRadii
                distanceFromBaseline
                checkBothContainsOther
                calc_ballUnitsAway
                these metrics for custom consition e.g. ball less than 20 pixels

            for all frames:
                checkTrackSuccess
                radiusVsRunningAverage
                you can look at these for balls <20 pixels if you go based off track instead
                    of score


1/25

    [x] How do a eval outcome_data? - with OutcomeData.eval() via EvalTracker class
    [x] what happens when you aggregate on nan's?
        [x] does it break, does it count nan as zeros thus e.g. lowering avg?
            it doesn't break; it also takes into account nan as ignored
        [x] sum, max, min, mean, median
        [x] do we need to control rows_requested for basic aggregatin? - Kinda, see above
        [x] note: we will want to filter rows for advanced summaries: 
            e.g. accuracy for balls < 20 pixels 

    Tasks
        [x] do some aggregating in notebook - df.mean() , df.min(), etc..
        [x] figure out an atomic template for each aggregation in notebook
        [x] start writing AggregatorClass
            [x] need to do absolute value for compareRadii
        [x] show aggregation after eval run on cli/subprocEval
            [x] allow DFHleper to handle AggEval df's, so we can pretty print to cli
        [x] start a new notebook
            [x] show subprocEval printing the agg_eval df
        [x] DFHelper returns a better way to format, copy EvalDisplay()
        [~] Limit Obj amounts on outcome_data; does this happen already?
            - already happens: EvalHelpers:768 - ev.setObjEnum(0) is harcoded
            - outcomedata-df still shows all obj's
        [x] calc'd fields
        [ ] EvalSuite.fullReport()
            [ ] multiple
            [ ] custom agg fields, e.g. balls < 20 pixels

        [ ] build a benchmark db and start interfacing with it from a
            
            EvalSuite class:
                
                .cliDisplay() - copy code from ControlEval:230
                .jupyterFullDisplay() - a full page display of everything

                - here's where you do diffs by frame and diffs by agg
                  vs the benchmark

                - this should support config for different 'reports' that
                we develop as we go forward

                - this can also include graphs e.g. compareRadii

                - this has different ways to compare: e.g. same video, diff algos
                vs. same algo, diff vids

            MasterDBInterface class:

                major issue: using sqlalchemy is difficult here for inserts
                    db -> db via sql might be easier?
                    how is the data actually stored in sqlite?

                relational: tbl for videos tbl for algos, tbl for basic runs

                insert instead of replace/update

                query returns data to EvalSuite as df


1/24 - 1/25
    
    Previous
    [ ] aggregate eval table elements
    [ ] multi-objEnum
    [ ] time perf for each frame from an eval run

    Also
    [ ] run a --dir for eval
    [ ] add a video properties table for each video:
        - e.g. dec14/output5.proc1.avi - ball-color:"green", frame-nums:345, ...
        - how do we uniquely identify a video (that may be moved?) with non-unique
        names within a file hierarchy? a hash of some property?

    Culminating In
    [ ] add this data for one video to a master-db
    [ ] compare the eval results from current run to baseline in master-db

    Misc
    [ ] how to auto-complete/auto-correct video paths?
    [ ] there are three point rays: when the ball bounces it looks like a 'V'
    [ ] why is checkTrackInsideBaselineRect < checkTrackInsideBaseline ? (should be opposite)
    [ ] fix checkTrackSuccess metric


1/16

    [ ] build speed-estimate-book using output-state
        [ ] zoom windows for end points
        [ ] use timelog from state to calc time interval

1/15

    investigate the diff-frame, diff-encoding situation
        [x] new notebook: encoding-issue-1.ipynb
        [x] mimic process of creating short/ss1 /ss2
        [x] add book data to git

    misc
    [ ] why is test data changing each time for: test/analysishelpers/subprocEval/test_eval_db.db

1/14

[x] add pandas-compare function to test
[x] add warning if --eval run w/o --track
[x] check the eval / delayFrame issue
[x] test a vid w/o a input-score in the first frame: do col-types change? no
[x] unittest: DFHelper methods
[x] unittest: add EvalDataset_buildDataset_2() with .equlas() and non input frames
[x] unittest: pickle.load from interproc
[x] test data uploaded to git

[ ] pathToData

[ ] rename test folder / allow import from it? rename to "tests"
    [ ] understand why guiview(line168) does work to import test
        it seems it works from a parent/sibling within the file 
        hierarchy; but not from a cousin file
        weird: couldn't get listConatinsSameElems() from test/utils into test/interproc_test.py
                but could get it into other moduleX_test.py
    [x] am i using ImgDiff anywhere? yes, controldisplay_test
    [ ] refactor imports
    [ ] refactor paths; so many; here's where you'd want pathToDatav / pathToTest

[x] Progress Bar
    [x] find num of frames from timelog or notesfactory (for progress bar) [already exists]
    [x] build progressbar for subprocEval; stdout.PIPE?
    [x] add timing to subproc
        notes:
            scratch/demo_subproc.py works
                need to flush() stdout after write()
                use tempfile module to avoid PIPE
                only need stdout, not stderr

[ ] aggregate eval table elements
[ ] multi-objEnum

[x] investigate the difference in tracking when a new video is created
    (as first ob served in eval-module-3.ipynb:ATTENTION)
    [x] verify that lossless encoding has equal tracks
    [x] verify imgDiffs (e.g. using test/utils.py:ImgDiff) in ss1 vs ss2

deferred
    [x] dfhelper datasetDisplay()
        [x] return the df itself
        [x] add asserts to evalhelpers_test:test_DFHelper_1()

misc/ideas
    [ ] "live" record/view script with tracking module deployed; "see the tracking" in
        realtime

1/13

    [x] add pandas-compare function to test
    [x] add warning if --eval run w/o --track

    ideas
        running --eval w/o inputframes is only recording track results
        but it could be logging frame notes

1/12

    tasks
    [x] unittest: evaldataset
        x add answer_outcome.db
        x add interproc.db
        x subprocEval collides with current output_dataframe db
        x can we change guiview --eval to have custom db path?
        x how to compare with nan's? nantonum via pd?
    [x] condensedTable inOutcomeData for evalData-df
    [x] demo these in eval-module-3
        [x] evaldataset
        [x] condensedTable
            [x] evalMethodNames for type='output'
    [x] add test data to git

    [x] unittest: pickle.load from interproc
    [x] unittest: subprocEval
    [x] unittest: DFHelper methods
    

    misc
        [x] find num of frames from timelog or notesfactory (for progress bar)

1/11

    10-11
    [x] helpers methods - copy from evalDataset
        [x] displayEvalMethodsNames - works for snake_case
        [x] deprecate old functions
        [x] unittests for them
        [x] demo in jupyter
        [x] make DFHelper.formatting_cols + DFHelper.col_order_default
            work when cols aren't present
        [x] unittest for EvalDataset

    [ ] multi-objEnum

    [ ] aggregate eval table elements
    [ ] test a vid w/o a input-score in the first frame: do col-types change?

    misc:
        [x] why is OD.evalData all zero's? ide-overwrite
        [x] fix cmp in test_outcomeData_eval()

    36d7ce4f4 b75e57345d

1/10

    [x] outcome -> listScoreSchema
        [x] add unit tests
    
    [x] in ScoreSchema: coerce all data-values to int (currently they are float and L)
        [x] addRay/ addCircle
        [x] load()
        [x] add unit tests

    [x] edge cases for ScoreSchema getAll() returns {} or None?
        -> returns None

    [x] apply eval to listScoreSchema simple

        [x] unittest

        notes:
            it's the try/catch in outcomeData.eval that's inserting nones
            when baseline score is wrong

    [ ] multi-ObjEnum eval
    
    [x] helper methods on eval data

    [x] allow None as a baselineScore / handle it

    [x] more unittests in evalhelpers_test

    tasks
        [ ] have we posted the speed estimation data?
            [ ] jupyter notebook showing the derivation
        [x] add new test data to git
        [x] correct failed tests
        [x] better docu for EvalDataset; it's really for applying eval to 
            a {tracker, listGS} - "see how your new tracker performed on your
            current frames-of-interest" without running full video eval and 
            re-isolating your foi's.

    possible bugs

        [x] np.NaN (presumably pd.NaN) can't be converted with int(); problem?
            yes - in cmp() for one
            [~] how to replace?
        
        [x] we really can't change outcome_dataframe field naming formula; how 
            to solidify this thru unit tests? what are the edge cases?

        [x] is timefactory off for --eval? yes

    other thoughts

        we'll turn loggin off in trackfactory for time measurment but turn it on
        when we want to debug

        a NN would "predict the next frame" from a segmented/masked image
        showing only the ball + its reflection & the config corners; you're
        not predicting an x,y,z path, but just the motion blur of the next frame;
        and from that you interpret is as position estimate


1/9

    tasks
        [x] change name on graphic function
        [x] add true x-values to b_all_frame=False
        [x] test displaySeriesPlot
        [x] refactor displayDiameterPlot() to simpler
        [x] demo how to sort/rank return data for specific frames
        
        10:30 - 11:30 
        [x] apply eval to outcomeData
            
            notes:

                EvalDataset expects self.df to contain the eval methods already applied
                that's the self.df element
                EvalTracker works on ScoreSchema.getAll() output
                but that includes all obj enums as dict which contain a type + data

                eval: compare input vs track
                properties: calc field on eval e.g. ballUnitsAway = centerDistance/ baselineRadius

            [x] probably need to return nan under certain track/input conditions

    bugs
        [x] both plots: legend is reversed
        [x] document f_pathfn better in subprocEval
        [x] appears to sort diameterplot-data wrong in eval_module_2.ipynb

1/8
    10:00 - 11:00
        [x] load() method in evalFactory / analysisHelpers
        [x] displayRelevant / filter methods in the class
        [x] pandas -> ScoreSchema
        [ ] unittests
        [ ] add frame-notes
        [ ] add track-notes e.g. currentTrackSuccess

    11:00 - 12:00
        [x] outputOutcomeData unittests
        [ ] aggregate eval dataset
        [ ] add tuples to sql
        
    12:00 - 1:00
        [ ] subproc wrapper
        [x] applyEval
        [ ] unit tests for --eval run

    other
        [ ] add trackTimer data
            [ ] this need to be logged multiple times for 
        [ ] other diagnostic plots e.g. x+y distance
        [ ] catch plt.show() and plt.plot() and override into subplot
            to form horizontal displayed subplots
    
    misc
        [ ] remove 'from itertools import combinations' from multiple modules
        [ ] progress bar for batchOutput()
        [ ] is long startup time in debug caused by ipython?
            "pythonPath": (in launch.json)?

    ideas
        [ ] document: 'track'= y_hat, 'input' / 'scored' = y

    Basic outputOutcomeData
    [x] data_fields in getScalarFields() needs underscore in naming

    [ ] Advanced outcomeData methods
        [ ] add tuple objects to pandas/sql
        [ ] don't need dump/load ScoreSchema into EvalFactory
        [ ] add notes to the table
            [ ] as a json object
            [ ] as scalars

    [ ] understand the properties of fields in pandas / sql
        [ ] what happens with None vs. np.NaN ?
        [ ] how does this affect aggregation ?

    [x] Refactor EvalFactory
        [x] eliminate eval_methods as output

    [x] Methods for the table; add these to a class
        [x] filter cols for one objEnum
        [x] filter rows for criteria
            [x] only rows with input-scores
            [x] only rows where track fails
        [~] apply eval dataset to 

    [ ] subprocEval enhancements:
        [ ] does progress bar print within subprocEval inside jupyter?
            it shouldn't because subproc is running in a shell
        [ ] make progress bar work in subprocEval
            using a pipe from the shell?
        [ ] how to make this work for multi-vid or multi-algo runs?

    Bugs:
        [ ] track_obj_exists_I is always true when tracking is turned on
            but it doesn't capture TrackFactory.currentTrackSuccess
        [ ] how to copy/paste pythonically in vscode?
        [ ] how to one button split window vscode?
        [ ] add a next video shortcut key for --dir runs
    



1/4 - 1/6

    [x] see if pandas dataframe can work to merge dicts of full_cols with
        particular frame's cols e.g. pd_base.addRecord({'scoreObj':0, ...})

    [x] add toScalars() and getScalarFields()
    
    [x] add pandas logic to outputOutcomeData

    [x] new idea: all just dictionary until final step

    Misc Extras:
        
        [ ] Extra Eval Methods:
            [ ] checkLocalMovement - is the ball in roughly the same region as previous?
            [ ] checkRadiusChange - is the ball's radius roughly the same as last time?
                [ ] add a plot across all frames

1/1 - 1/4

    [x] rip out current EvalModule; replace with trackScore and inputScore properties
        only
        [x] how do we handle 4 objEnum's?
            for each objEnum: we have a 'type' and the 'data'
            how do we handle tuples/list in 'data'?
        
        [x] write tbl col names within scoreSchema ?
        
        [ ] also we need notes on that frame

        [x] how do add a scoreSchema object to a list with deep copying?
            [ ] write unit-test / pandas

        [ ] how to store tuples in pandas?

    [ ] Test / Note any features needed for "adding challenge frames iteratively"
        via guiview workflow

    tuples -> sql

        [x] ScoreSchema.toScalars() / .fromScalars()
            for each obj-type (ray vs circle) we decompose into scalars
            but what 
             - the main issue here is we may have unexpectedly add columns
               for a new type of object
             - if some records have int's but other have nones does that make
               the sql data tables incompatible?
        
        [x] object in pandas then df.to_sql(), then we can get tuples out?
            [ ] can we get a tuple out of an entry
            [ ] how are tuples saved in sqlite?

        [ ] another way to do it to create a record for each scalar in a separate
            table with a join to the frame_eval_table

        [ ] another way is with ORM e.g. sqlalchemy

        [ ] can use a combination of these styles: e.g. DF = 
            data_type   data_object     data0   data1   ...
            ray         ((1,2),(3,4))   1       2       ...
            circle      ((5,6),(7,8))   5       6       ...
            where we have object/tuple AND scalars

    within EvalFactory we can have the loadEvalData() function as well as methods to 
    apply the evalMethods.

12/28

    [ ] Pandas work: filtering + calcd fields + aggregated fields
        
        https://pandas.pydata.org/pandas-docs/stable/10min.html
        [x] filter
        [x] calc'd field: distanceFromBaseline / baselineRadius
        [ ] aggregated: % True?

        [ ] refactor these separate methods into one

    [x] eval-data-2 demo of how to visually explore specific frames

    [x] compare tracker algoenum=1 vs algoenum=2
        [x] need to add this to subprocBatchOutput

    [ ] build eval module

        [x] basic skeleton and results
        [x] how to pickle it into sqlite?

        TODO
        [x] need to add tracker score properties
        [x] need to add inputscore properties
        [x] why do we even do eval inside guiview? all we need is those properties
        [ ] difference of each frame for different algos
            [ ] for boolean: improvement or regression?
            [ ] for number data: improvement or regression?

        Milestones
         - an aggregated table for each video and each algo, showing perf diffs

        Things to Think about

            We'll want to add challenge frames as we iterate. The easiest way
            to do this is create a new video copied from previous with extra 
            inputScores. But this would create tons of processing for multiple
            of the same video (or more vexxing, slightly different amount of frames
            due to user error in video creation). But this creates a problem
            where we don't have the evaluation for the new scores on the old algos.

            -> this could be avoided by doing having evalFactory only output
               trackScore and inputScore properties, then doing eval as a 
               post-processing / calculated field type thing. "we want eval but
               we don't have to calc it right there"
               
            -> new recipe: cp the file then write (/ override ?) scoring / notes 
                which preserves the videos frame amount.

        Misc fun stuff
        [x] progress bar
        [x] keypress cv2 -> tkinter
        [x] turn off semiloaded/preloaded for eval runs?
    

12/27

    [x] finish batch-output
        [x] test list cli option
        [x] add this to commands.txt; anywhere else? say docs?
        [x] verify program flow w/ debugger
            [x] can we grab first frame with our conditionals in criteria?
        [x] commit to git

    [x] build the new dataset
        [x] use the criteria to output all scoring states
        [x] verify this in a jupyter listGS

    [x] subprocess wrapper for --batchoutputlist calls
        [x] wrapper
        [x] dbpathfn for output

    [ ] build some tests for these functions
        [x] need --dbpathfn for mock testing of db writes
        [ ] test the guiview itself
        [ ] test the subproc

    [x] new book: eval-data-2:
        [x] restrict imports to essential + condense
        [x] add db to ppd_data repo
        [x] eliminate some eval fields
        [x] recipe for filter-table -> get-particular gs's -> analyze in detail
            [x] also with comparison to "good" gs
            [x] mask progression & pcm plots

12/26

    [x] finish previous tasks
        [x] build new dataset
            [x] 10 challenge frames
        [x] add these new scores to analysis book
            [x] how to keep 'em separate? 
                [x] frameCounter index "not in"
        [x] pandas
        [~] fudge value on pcm

    [x] add buildEvalData functions to modules
        
        [x] new module

        [x] copy over EvalTracker class
            how to repair all instances of from AnalysisHelpers import EvalTracker?
            -> ctrl+f; wasn't many
        
        [x] add a single function that does em all
        
    [x] a class for the dataframe:
        [x] rename(columns = )
        [x] df.format.style()
                https://stackoverflow.com/questions/48243818/display-column-name-different-from-dictionary-key-name-in-pandas
        further styling for pandas:
            https://community.modeanalytics.com/gallery/python_dataframe_styling/


    [~] FrameTrackObject class

        we don't need full guiviewState object, just orginal-frame + notes + misc(?)
        -> this should be default object to iterate over instead of listGS

            [~] refactor listGS to list_fto
    
    [~] build EvalData for whole video
        
        [x] how do we get gs's for each frame?
            
            a utility in guiview? 
            or FTO conversion? 
            we want to emulate the 1-line r/w to disk functionality of GS though
            each gs for a whole video is too large, we're not getting 20x vid compression rate
            so any gs or even fto is too cumbersome to pickle into a db for the whole vid, especially high framesize ones
            
            instead we need a guiview like program to run frames > 20 batches:
                with evalTracker / evalDataset in the inner loop
            why can't we just bring EvalClassX's into guiview?
            
            what batch_output_state would be good for is detailed viewing/plotting for misses:
                a second procedure that runs on a filtered dataframe for certain characteristics
                e.g. checkTrackInsideBaseline = False for output5.avi
                this can be called semi-automatically from evalDataset
                so many criteria will just be lists of frameCounters, 
                    need to be passed in cli? call guiview as a subprocess with show=off?
                    use a json file to r/w the frameCounter list?
            
        
        [x] finish batchenum feature
            [x] list of frameCounter inputs
            [x] delete all interproc states before start
                [~] or separate --dbpathfn with custom name
            [x] add pre- and post- print message
            [x] suppress "outputting state..."
            [x] exit after run thru
            [x] subprocess that calls guiview with --batchoutputenum <arg> --nogui --showoff
                and returns listGS

        [ ] build vid_eval
            [ ] what form: as guiview submodule EvalFactory with --eval ?
            [ ]  where does the data go after process is terminated? as a pickle/db write?
                [ ] a subproc wrapper for this
                [ ] a vid_eval.py alias for this that calls subprocess on guiview.py --eval
                [ ] --dbpathfn to eval_output5_2018.12.29.11.13.11.sqlite
                [ ] how to avoid adding this table to master_table in the db before it's verified?
            [ ] add calculated fields, e.g. = compareRadii / baselineRadius
            [ ] baseline vid_eval will not look at track_log, that's only as indv frame
                level / n < 20 leveli
            [ ] feed in multiple sources of data to dataframe from non-frame sources 
                e.g. time, notes, trackertime, etc.

        next steps

            [ ] aggregation of table data
            [ ] basic db-interface
            [ ] validation -> insertion to master table
            [ ] how to update/add to master_table schema?
            [ ] batch algo / batch vid runs
            [ ] multi-algo / multi-vid comparisons

        misc
            [ ] progress bar
            [x] call with --startplay or whatever
            [ ] how to handle score vs unscored frames?
            [ ] show how to sort for this
            [ ] show how to aggregate in the face of this
            [ ] need a --stopcriteria similiar to --batchoutput but for stopping in guiview


    
    There is a hierarchy to batch eval

        for each {tracker, githash, init_policy}:

        directory / vidlist
            video
                (init stage)
                frame
                    (scored vs unscored)
                    trackPerfMetric
                        (various methods)
    
    Connery the Cop - C + JS

12/20

    [x] build new dataset w/ challenges

    
    [ ] improve EvalTracker class
        [x] checkEitherContainsOther()
        [x] updgrade insideRect to insideCircle()
        [ ] add a fudge-value for inside() functions (1 or 2 pixels? prop to radi?)
        [x] put these criteria in notebook as a table
            [~] can you find an example where insideTrack=T;insideBase=F?

    [x] 2:30 - 3:30
        [x] side-by-side eval results
        [x] need drawTracker(), drawOperator()
        [x] verify origFrame is not altered by these methods
        [~] need a load/re-save for new method in GuiviewState
            this can actually just be handled by reload(GuiviewState), 
            and re-instatiate as gs = listGS[0], then call gs.newMethod()

    [x] 3:30 - 5:00
        [x] demo getScoreWindow(bScoreFrame=True/False) in notebook
        [x] expand score window

    [ ] 7:00 + 
        [x] copy over evalTracker stuff to analyze-orange-2
        [x] delete the trailing cells in analyze-orange-1
        [x] implement eval tracker for good_gs, bad_gs
        [x] put them in pandas
        [x] then do the eval suite on all tracked frames
        [x] new dataset,
        [x] import new dataset
        [x] eval suite on new dataset
        

12/19

    [x] add colorInRange to AnalysisHelpers
    [x] make colorInRange() multi-thresh
    [x] modify existing orange thresh
    [x] add second thresh to orange hand-drawn
    [x] do a PCM on each orange frame
    [x] add to threshes to TrackFactory; observe
        [x] diagnose new tracking perf in new notebook
    [ ] how to do one PCM on multiple frames?
    [ ] build new coordinates: distance from origin line

    [ ] new book: analyze-orange-thresh-1
        [x] PCM's for all frames
        [x] tracksuccess table
        [ ] build new dataset of guiviews of track misses
        [ ] try changing threshes to more stringent red-min value

    bug: guiview shows scoreWindow (not-"n/a") with failed track
        on oct20/output5.avi frame_i=210

    

12/17

    Crash course for images
    https://www.scipy-lectures.org/packages/scikit-image/index.html

    https://docs.scipy.org/doc/numpy/reference/routines.array-manipulation.html



12/15

    [ ] build boosted iterThresh

    [ ] bug? IterThresh.py:208:
            ''' for clr_i in CLRS:
                     if clr_i in clrs:  '''
    


12/14

    [x] verify interactive graph still works
    
    [x] iterThresh debug gallery

        [x] build dataset
            [x] build some output states similiar to trainingSteps
            [x] get the close out of range too
            [x] get an orange ball too
            [x] build output state db; should have displayInputScore
                [x] how to get pseudo-zoomWindow based on scoreDisplay?
            [x] repeat score->output with orange ball for interproc4.db

        [x] commit these bug fix: multiPlot, interProc, tracker, buildConfusionData
        
        [x] iterThresh stepwise + update regionMarkers

    [ ] build better region classifiers

        [ ] hand-drawn distance from the origin separators

        [x] use sklearn to segment
            [x] first on 2D data
            [x] then on 3D data
            [~] how to force data points in nether regions thereby forcing "full green"?
                [~] maybe be sampling in and out data mean/sd and then randomly sampling
                    from that space

            [~] cubic fill for continuous model score

    [ ] try HSV segmentation
    
    [ ] output all states with a certain condition
        guiview --filter-condition=
        this could be like test_enum 7 where all class go into an interface
        then check for conditions on those elems

    Mop-ups:

        [ ] ImgUtils.pixlist_to_pseduoimg (typo)
        
        [ ] use mutliplot with mutli colorplots using 
            biggerPic() is cc-gallery-3.ipynb
        [ ] need pseudo-FP, pseudo-FN where the "True Circle"
            is 2 smaller / larger respectively
        [~] bug guiview: scoreDisplay is not n/a when trackSucess=False
            - best way to view on the fly tracking misses is with 
              'annotate obj' turned on, so you see the number dissapear
        [x] bug guiview-state: zoomWindow doesn't work on 1280p
        [x] bug applyTracker(): need to reset tracker each iteration;
            this could be related to the bug above; NOT COMPLETELY
            is this why oct20/output4 is now "solved" for all frames? YES - actually it's "unsolved"
        [ ] bug guiview: the score rect's are "off", how did that occur?
             - maybe via going back frames while recording them?
             - maybe because we're skipping first ~18 frames from beginning
                and thus they're lagged behind?
             - as seen on dec14/output6.proc1.avi frame 78 and further
             - can this be corrected in reprocessing for now?
12/13

    [x] multi-OR-thresh in tracker
    [x] human readable confusion output
    [x] preplanned azim/elev slices + function
        [x] gonna involve multi-img plotting
        [x] modularize regionMarkers function
    
    5:00
        [x] cleanup and commit work


12/11 - 12/12

    [x] --dbpathfn used, how does it work with colorcub-gallery.ipynb?
    [x] document the flag in commands.txt
    [x] document the flag in class definition
    [x] commit the gallery-1 and associated data
    [ ] bug: SubprocColorCube can not load old interproc_colorcube.db data when class
        elements have been changed like addition on dictData as an arg
    [x] modularize the regionmarkers
    [x] make colorcube-gallery-2
    [ ] colorcube gallery, get a few figures in there:
        [x] replicate existing red/blue disnction
        [x] add FP/FN color markers
        [x] modularize function
        [x] multiple balls (from multiple frames) 
            [x] far away and close
    [x] modularize plotting a confusion matrix
    [ ] allow multiplot grids; use tk.save()? pass in a global plt to separate functions?
    [~] definedVolume near where the 3 key metrics are:
        [~] CI for each of the three masses
    [x] make in-notebook plot larger
    [~] decrease whitespace
    [x] add color legend
    [ ] build preplanned azimuth/elevation tuples 
        [ ] function that does of each, horizontally
    [x] add title
    [x] do 10,000 point plot
    
    [x] build basic numpy operators
        [x] use cv2.bitwise_and(mask1, mask2)
        [x] build modularized functions for tp/tn/fp/fn

        https://stackoverflow.com/questions/44865023/circular-masking-an-image-in-python-using-numpy-arrays

    [ ] build PixelConfusionMatrix class
        [x] does calculation of threshold
        [x] accepts new threshes, new images, new masks
        [x] outputs in machine readable form
        [x] output in human readable form
        [ ] roc over threshold
            [ ] how to make expanding threshold 1-dimensional?

    [x] add a second or-thresh
        [x] view in colorcube
        [x] apply to confusion matrix module
        [x] apply to tracker
        [x] multi-thresh: bitwise_or

    [ ] slice the colorCube diagonally
        [ ] can do a cubic fill
        [ ] timeit function
        [ ] how can we do it elegantly?
        [ ] use solids on 3d plot, to easily filter
        [ ] can use sklearn type segmentation algo's

    [ ] use iterThresh with the colorCube

    [ ] contours historgram

    [ ] repairA appears wrong: erode and dilate should run in a loop, not
        one before the other.

    [ ] explore hsv

    [ ] add all this stuff to a PolicyManagement module with training+iterThresh


    

12/10

    back at it...

    misc notes

        color cube colors: green for TP, red for FN, yellow for FP, blue for TN

        add dude perfect video and cronin competition vids

        color transforms for colorCube? e.g to accentuate yellow

        rolling shutter creates positioning problems where the beginning of the roll
        records the actual ball, and

        which way does rolling shutter roll? how can that be exploited? how can
        that be demonstated?

        can i prove that positioning concept actually "works" - resolves a unique 
        3D position from two 2D images. has to work with the proposed experimental
        setup and in the full volume over the table

    major goals:

        review the current uncommited items, complete them, add them in.

        review the notebook situation and do a new one with colorcube

        review outstanding items, sort into two groups, todo and deferred        

    Todo

        [x] move regionMarkers hfunctions into module
        [ ] multiple balls (from multiple frames) 
        [x] plot with dif markers
            [x] 1: thresh-in / thresh-out
            [x] 2: in-score / out-score
        [ ] add stateOutput to docs
        [ ] pathToData
        [ ] change db name from 'demo' to interproc
        [ ] helper functions
            [ ] multi image subplt
            [ ] crop for zoom window
            [ ] orientation for view
        [ ] histogram for num contours
        [ ] separate mask from object selection
        [ ] add buildGradient, combineGradient and combineDicts to Module
        [ ] better checkTrackSuccess...verify the track is near where the ground-truth
            score is
        [ ] new book, use interproc and interThresh
        [ ] we really need to get trainingFrames going
        [ ] function that finds the full circle from zoomWindow
            [ ] isAPseudoCircle
            [ ] find circles in un-transformed image; hough's circle finder?
            [ ] fit a circle to object
            [ ] extract the pixels from this shape, and re-calcs
        [ ] second largest obj in mask
            [ ] but not another portion of the ball
        [ ] how to get baselineScore? when it's a FP like frame189
            [ ] easy way to get rect interactively from guiview:
                a one-liner in jupyter; build this as importable function
                [ ] close db connection after function use

    Deferred

        [ ] regionMarkers helper - expandVolume(scalar, constant)
        [ ] other color utils - color hexagon w/ mouseover
        [ ] why don't "buttons" / controllers on tk-matpltolib work? e.g. zoom
        [ ] modularize paramSpace functions
        [ ] try volumes, work better than regionMarkers?
            [ ] improved ImgUtils:filter_pixels_circle [with circle input]
            [ ] need to add boundary in colorCube
        [ ] have guiview show the colorplt in realtime
                [ ] do a function of searchParams
            [ ] timeit - time per iter?
        [ ] buildGradient for full combination on tuple
        [ ] trackFrameDemo3 - separates mask and selection
            [ ] b_log returns countours data
        [ ] tests for SerachParams functions


11/26

    [x] plot with dif markers
        [x] 1: thresh-in / thresh-out
        [x] 2: in-score / out-score

    [x] set interproc_colorcube.db pathFn
    
    [ ] try volumes, work better than regionMarkers?

    [x] move regionMarkers hfunctions into module

    [ ] multiple balls (from multiple frames) 

    [x] improved ImgUtils:filter_pixels_circle [with circle input]

11/25

    [x] verify you can delete interproc_colorplot.db and recover
    [x] finish a demo-subproc-colorcube book and commit it
        [x] how to copy the interproc db into books-data
        [x] explain the %notebook problem
    [x] how to use interproc.db for testing
    [ ] finish a colorcube-gallery-1 and commit it
        [ ] show bunch of different colorCube slices / analysis-types on listGS
        [ ] do ball inThresh vs outOfThresh
    [x] keypress to output data in subprocess
        [x] simple
        [x] complex
        [x] how to get fig.get_axis()
    [x] refactor colorPlt -> colorCube
    [x] add animation? - no!
    [ ] need to add boundary in colorCube
    [ ] have guiview show the colorplt in realtime

    [ ] this will be great for iterThresh display debugging
    [ ] would be nice to have a way to show plt side-by-side or 
        for any arbitrary display-setup
    
    9:30 +:
        [ ] regionMarkers
            [ ] 2nd scatter

        [ ] regionMarkers helpers
            [x] threshToVolume
            [ ] expandVolume(scalar, constant)

        10:00
            [x] get some data
            [x] work on adding regionMarkers
            [ ] then if 2x scatter works, do a second scatter for in/out

        11:00
            [x] build edgesFromCorners


        notes:

            matplotlib gallery

                3d volumes
                https://matplotlib.org/2.1.1/gallery/mplot3d/voxels.html#sphx-glr-gallery-mplot3d-voxels-py

                3d scatter
                https://matplotlib.org/2.1.1/gallery/mplot3d/scatter3d.html#sphx-glr-gallery-mplot3d-scatter3d-py

                shapes with opacity
                https://stackoverflow.com/questions/48672663/matplotlib-render-all-internal-voxels-with-alpha




11/24

    [x] verify neither %matplotlib notebook or separate tk.matplotlib is more
        responsive: FALSE: matplotlib-notebook is semi-responsive at sampleN=200,
        while matplotlib-subproc is responsive at sampleN=2000, and semi-responsive at 
        sampleN=5000 so a 10x diff

    [x] investigate if you can:
         get the current-view-params for an interactive figure
         set the view-params for a static figure
            - we can view params in figure subtitle bar; are they sufficient?
                azimuth, elevation

            - apropos: https://stackoverflow.com/questions/12904912/how-to-set-camera-position-for-3d-plots-using-python-matplotlib
                ax.view_init(elev=10., azim=ii)
                axx=ax1.get_axes()
                azm=axx.azim
                ele=axx.elev
                dst=axx.dist      

    [ ] why don't "buttons" / controllers on tk-matpltolib work? e.g. zoom


11/23

    [x] build SubprocColorPlot
        [x] db interface

    The goal with SubprocColorPlot was to create a separate TK window outside 
    jupyter to more easily rotate the figure for exploration. This has proven 
    very difficult with jupyter: so far we need to go into cmd-line to get it 
    to work. 

11/22

    [ ] build some 3d plot utilities
        [x] convert image to channels
        [x] interactive run from subprocess in jupyter
        [x] run highly limited one in notebook inline
        [x] sampling function
        [x] axises croppping vs full length
        [x] axises labelling and shifting
        [x] true colors for markers
        [ ] two colors: obj vs background

    [ ] demo 3d analysis:
        [ ] subimages within an image
        [ ] plot score-circle pixels vs. whole image
            [ ] extract circle pixels
        [ ] can you switch from %matplotlib inline <->
            %matplotlib notebook

    [ ] other color utils:
        [ ] color hexagon w/ mouseover

11/21

    [x] build data for search-params-1.ipynb
    [ ] how to get baselineScore? when it's a FP like frame189
        [ ] easy way to get rect interactively from guiview:
            a one-liner in jupyter; build this as importable function
            [ ] close db connection after function use
    [x] build searchParams module
    [ ] do a function of searchParams
        [ ] timeit - time per iter?
        [x] use Evaltracker class
    [ ] buildGradient for full combination on tuple
    [ ] trackFrameDemo3 - separates mask and selection
        [ ] b_log returns countours data
    [ ] tests for SerachParams functions
    [x] fix id'd 'Problems' from language server

    3:00
        [x] commit minor fixes
        [x] commit new module, new data
            [ ] first some unit tests
        [x] commit new notebook
        [x] plot of working params
        

    4:00
        [ ] new book, use interproc and interThresh
        [ ] we really need to get trainingFrames going
        [ ] label axises on paramSpace scatter
        [ ] modularize paramSpace functions

    Also want:
    [ ] function that finds the full circle from zoomWindow
        [ ] isAPseudoCircle
        [ ] find circles in un-transformed image; hough's circle finder?
        [ ] fit a circle to object
        [ ] extract the pixels from this shape, and re-calcs
    [ ] second largest obj in mask
        [ ] but not another portion of the ball


11/20

    [x] test applyTracker with window function
    [x] save/load states to a db
    [ ] use listScore to view a thresh hit
    [x] tests for AnalysisHelper functions
    [x] keypress 'O' for output-state
    [x] rename freaking db to interproc
    [x] inWindowCheck()
    [ ] vscode: halve the screen for working with jupyter
    [ ] jupyter: get code complete for own functions, imported libraries
    [ ] jupyter: remove yellow syntax highlighting
    [x] remove print 'here' in output-state cmd

    [ ] 7:00 +
        we want to for-loop thru 
        [x] we need to eval tracker
            this will help us say yes or no if a param point worked
        [x] we need to not output listPlts from applyTracker if told not to
            this will save time/memory for vast param search space
        [x] function for param gradient
        [x] combine two param gradients
        [x] then write one of these loops
        [x] show how to display transforms of successfully tracked paramPoints
        [ ] better checkTrackSuccess

        [x] git push data
        [x] git push notebooks

    Also want
    [ ] histogram for num contours
    [ ] separate mask from object selection
    [ ] add buildGradient, combineGradient and combineDicts to Module
    [ ] better checkTrackSuccess...verify the track is near where the ground-truth
        score is
    

11/19

    [ ] Build example notebook

        [ ] show-me:

            [ ] track un-tracked ball with manual thresh change

            [x] show image pipeline of each step in track

            [x] for-loop checking different thresh's

        [ ] bugs:

            [ ] TrackFactory(on=True) is confusing in Ipy; always forget, it's
                not verbose so it's vexing

        [ ] helpers functions:
            [ ] pass-thru score window
            [ ] pass-thru zoom window
                [x] basic
                [ ] input_rect
            [ ] display windows
            [x] tile function for multiple images

        [ ] build importable classes that use Display to produce output

        [ ] ipy widgets
            [ ] slider

    [ ] first commit:
        [ ] draw tracking score on multiplot; show which contour is being used
        [x] subplot titles
        [x] add a third image scenario...a difficult but sucessful track
        [ ] need to analyze not only zoom window but whole frame

    [ ] 2:00 - 3:00
        [x] keys for unpacking data of images
        [x] subtitles for graph
        [ ] flip axis on graph
        [x] 3rd image
        [ ] getLatest(last=3)
    
    [x] 3:00 - 4:00
        [x] test with no img_mask_2 image
            [x] this exact case does not occur; need a better example
            [x] add sum(sum( as condition for advancing in trackFrame
        [x] turn off repairIterations
        [x] add evaluation of whole image / is tracked obj center in zoom window
        [x] generalize buildData for different crop selections
            [x] rename buildData()
            [x] add this to a module

    [x] 4:30 - 5:30
        [x] call multiple tracking algos
        [x] pass in trackAlgoEnum to guiview
        [x] add second trackAlgo
        [x] pass-in objEnum to trackAlgo
            [x] add this concept to template documentation

    [x] 5:30 - 6:30
        [x] turn off repairIters
        [x] answer questions in trackDemoNew()

    [x] 8:00 +
        [x] helper functions -> module
        [x] demo-interproc-analysis-2
        


11/16

    [x] first commit: better interproc data
        [x] zoom-window, score-window coords
        [x] add reload advice: altered method vs new method
        [~] helper class; demo in ipy
        [x] incrementing primary key for state_tbl
        [x] function to get latest state from state_tbl

    [ ] second commit: demo of tracking iteration
        [ ] pathToData
        [ ] change db name from 'demo' to interproc
        [ ] helper functions
            [ ] multi image subplt
            [ ] crop for zoom window
            [ ] orientation for view
        

    [ ] third commit: unit tests for this? it's gonna be hard
        [ ] help figure out instance inheritance:
            best insight: __new__(cls,)
            https://stackoverflow.com/questions/1382871/dynamically-attaching-a-method-to-an-existing-python-object-generated-with-swig/1383646#1383646
            https://docs.python.org/2.7/reference/datamodel.html
            https://stackoverflow.com/questions/14177788/init-child-with-parent-instance
            https://pypi.org/project/Acquisition/
            https://stackoverflow.com/questions/1081253/inheriting-from-instance-in-python
            https://stackoverflow.com/questions/1911281/how-do-i-get-list-of-methods-in-a-python-class
            https://thepythonguru.com/python-inheritance-and-polymorphism/

        [ ] add stateOutput to docs


    Misc
        [ ] tkinter in a better place - mid screend
            root.geometry("+800+800")
            https://yagisanatode.com/2018/02/23/how-do-i-change-the-size-and-position-of-the-main-window-in-tkinter-and-python-3/
            do this with other misc stuff
11/15

    Checkpoint todos:
    [ ] clean bugs
    [ ] add documentation
    [ ] add supporting notes
    [ ] add tests
    [ ] workthru the workflow; surfacing bugs
    [ ] refactor file hierarchy
    [ ] add some more data sets
        [ ] bounces
        [ ] process some datasets
    [ ] ipy-interproc
        [x] add sqlite
        [x] add to guiC
        [ ] do an ipy example with missing track in output4
            [ ] expand color thresh and succesfully track it
    [ ] evaluation

    List of bugs:
        [ ] make it noisy when an empty timelog is output from guirecord of guiview
            [ ] can you replicate it happening?
        [ ] vscode - prevent file explorer from expanding subdirs of open files
        

    [x] timelog - interval

        [x] examine some intervals corresponding to motion
    
    [x] what do both columns mean?
        specifically is one interval contained within the other? yes, 2nd is contained within first
        1st column timelog.log_frame_time (list)
        2nd column timelog.log_start_Time (list)

        log_start_time is the time spent on the cam.read() api call
        
        log_frame_time is the time spent in the whole loop

        individually, this could affect frame-t to frame-t+1 but overall, this shouldn't
        affect fps over a broad interval as log_frame_time is 

            [x] unless they impact each other in methods? verify they don't
        
        [~] timelog - data = [x[0] for x in data] is worng should include both columns
            -> no, 2nd column is contained in first

    Ben H Bell - ServiceBot, NLP ala Alexa

    So columns are OK as is, why is my data not making sense?
        [~] the no ret-handling in guirecord

        [~] the data is making sense; you're interpreting it wrong
            -> this data was collected incorrectly (output3, output7) 
               so we can't align the frames in th video to the timelog 
               entries, and there is significant drift for fps, so we
               will not be able to extract speed from this data; need to redo
            (actually, we can by counting frames in video, N, and taking last N
            entries in timelog)

        [x] why is timelog so long for output3 and output7; reproduce
            [x] do two recordings - YES, this is the problem

    Needed steps:

        [x] fix timelog issue
        [x] make sure ret handling will be noisy and apparent
        [x] repair existing datasets timelog
        [x] guirecord.jsonc populated
        [x] new data sets
        [x] calibrate light to high fps
        [x] build example low-light/low-fps example vid
            [x] build a book for this
        [x] extract speed data
            [x] throw_1/out7
            [~] throw_1/out3
            [x] throw_2/...
        [~] examine intervals corresponding to motion frames; do peaks
            correspond to perceived longer exposure? of-by-one?
    

11/13

    [x] organize demo speed data 
        [x] add excel to binary .gitattributes

    [x] build a book showing fps diff in low light conditions

    [x] fix timelog to account for 

        [x] why did I never account for both columns before?
        [x] what do the two columns mean exactly?


11/12

    [x] do some speed calc vids
        [x] lob ~17 mph  - output1
        [x] hard throw  - output3 / output7
        [x] easy throw  - output3 / output7

            output1, first attempt 15fps, lobs
            output3, second attempt, 17fps variety pack
            output5 dummy living room, 15 fps
            output4 - another try, no divorce
            output6 big lamp turned on, working
            outout7 - in earnest

    [x] why is logitech giving us 15fps not 30fps?
        -> too dark => too slow

    [x] can't replicate in kitchen, try again?
        [x] 17fps observed in production
        [x] timelog indicates regime shift: 30 -> 15 fps at frame ~900
            [x] why not in long vid?
            [x] looks like it's low light in living room vs kitchen (high light) 
                that's setting to 15 fps
                [x] verify this w/ low light kitchen
                    nov_calib_1/output8 - just light
                    nov_calib_1/output9 - switch b/w light and dark
    
    [x] test discrepancies b/w videos
        [x] does apparent speed match calc'd speed?
        -> looks about right b/w dif vid's have same apparent and calc'd speed: 10-20 feet/sec

    [x] can we see a timelog over a short interval?
        [x] if not, add this
        [x] how much different could off-by-1 or off-by-2 vids be? +50% / -33% with logtiech

    [x] why does 'true time' not work for output3? (it plays at ~2x speed)
        [x] why does output3, at 17 fps have 30 fps lag times for indv frames?
            [x] roughly 2800 frames for output3 according to timelog?

        [x] why is total cumtime in output3, output7 so wrong 143 and 193 respectively?
            [x] bc they are semi-loaded?
            [x] but output1 is fine?
                [x] it's not semiloaded
            [x] output1 has 350 frames while output3 and out7 have 3,500 frmaes?
                according to guiview out3 has ~420 frames, output7 ~740 frames
                (note: b/c the fps is much higher in )
            [x] is it because ret=False and guirecord doesn't handle that?
                [x] can't replicate though, even with darkness
            [x] try making a shor proc video that won't be semi-loaded

            -> b/c "end time" 2nd column is not included in analysis

            [x] does output3.txt has 3500 entries?
                [x] i think it starts logging when before record is toggled?
                    no...
                [x] because it keeps logging after record is off?
                    [ ] is this on 2nd video of seesions or 1st?


11/9

    BUGS + FEATURES

    [ ] guiview --output is unused
    [ ] guiview gui  'diff win' -> score window
    [ ] stop at certain frame (or start at that frame)
    [ ] only view frames where track doesn't find a ball, and notes
        indicate that ball_present=true; this will help us review for
        "challenge" locations to mark, or override notes and set 
        ball_present=false; name this concept:
    
    
    TODOS
    
    [x] make sure data repo is considering media files as binary with git diff
    [x] what commands to clone the both repos from github (w/o file renaming)
        [x] add this to documentation
    [x] add dependency like .dlls to data-sub-repo
    [x] update any paths in books or timelog_bench to the data folder

    [x] add documentation folder
         https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet
    [x] add .gitattributes with png
    [x] add project readme
        [x] link to ppd_data
        [x] link to documentation
    [x] add documentation notebooks
    
    [x] add documentation overview / markdown
        [x] "todo" for the doc's missing
    [ ] search commands.txt for lost options
        --framelog
        --scoreoff
        tail -f x/x/outputX.metalog -n 10

    [ ] better markdown bullet list formatting
    [ ] add helpful hints like how to debug, how to write tests, etc.
    [ ] add a wiki for open questions, and past progress, diagrams, etc.
        [ ] diagram to registering ball against screen
        [ ] video of drone actuation
        [ ] video of drone flight, with measuring stick -> accel params

    [ ] refactor miscutils + data
        [ ] refactor apps/modules that reference them
        [ ] refactor their own tests paths to data
    [ ] refactor tests in extraneous 
    [ ] one click testing
    [ ] remove .cache / .pycache from ppd root dir
    
    [ ] diagnose and eliminate ipython from launch.json (see notes/adapt_thresh.ipynb)
    [ ] build module reload ipy template
    [x] clean ppd's parent folder
    [x] clean scratch/
    [x] clean notes
    [ ] move .json's out of notes/
    [ ] assume-unchanged the .json's
    [x] add ppd_papers to data
    [x] collate .txt's into 1 notes
    [x] separate notes into categories
        [x] collect a savoire-fair list of cli tricks
    [ ] build some media-rich ppt's of notes; and a narrative breakdown

    [ ] refactor app's into scripts/ or something
        [ ] horizontal imports?
        [ ] 
    [ ] separate relevant scripts from legacy scripts
    [ ] build requirements.txt
    [ ] build a venv that runs the workspace: scripts + pass tests
    [ ] try workspace in wsl: that'll be hard for graphics of the video windows
    [ ] add vscode to personal github repo


11/8

    [x] first commit
        [x] fix 361 bug
        [x] prove by processing nov2018/output3
        notes:
            debug recipe:
            g.initWriteVid = True
            g.writevidOn = True
            g.playOn = True

            outputFact.checkWriteFrame()
                self.bWriteFrameCmd = False on 361

            what is IPythonHistorySavingThread in debug call stack?
                ->When running basic-run or guiview or some kind of launch item...
                  this is seen in console:
                    Python 2.7.13 (v2.7.13:a06454b1afa1, Dec 17 2016, 20:42:59) [MSC v.1500 32 bit (Intel)]
                    Type "copyright", "credits" or "license" for more information.

                    IPython 5.3.0 -- An enhanced Interactive Python.
                    ?         -> Introduction and overview of IPython's features.
                    %quickref -> Quick reference.
                    help      -> Python's own help system.
                    object?   -> Details about 'object', use 'object??' for extra details.
                    PyDev console: using IPython 5.3.0

    [x] second commit:
        [x] fix ray select in zoom window
            [x] this will pickup another deferred bug
                can't find exact match to these; looks like they should be OK thoughts
                we can reject these defects with a unit test on display:
                    just need to validate that the region selected is region saved and displayed when orientation != 0

        [x] fix profile view for score_dsiplay
            only happens when track turned on initially, eventually corrects itself...but now doesn't
            oh so this is connected to bug below
            [x] why does notesScoring interspace between tracking? in output3.proc1
                b/c soreRect is being built but we're keeping bShowScore=False, but trackOn=True
            [x] why does a non valid track roi get drawn onto score_display?
                -> need to reset display score each frame?
        [x] new bug: output3.proc1 w/o and cmds: unhandled err on frame_i=29
            note: display.scoreOn basically means notesFactory at that frame has a non-null scoring entry
            not that we've request a score_display

    [x] action 2.5, more bugs:
        [x] why can't I write scores to output3.proc1 ?
            debug recipe:
                g.initWriteVid = True
                display.outputScore.addCircle( (100,100,50,50),0)
                g.switchWriteScoring = True
            problem:
                main = self.getFrameScoreCurrent() is None instead of {}

    [x] action 2.75
        [x] can't write a ray roi to main_display with orientation != 0


    [x] third action:
        [x] research repo in repo
        [x] dummy repo in repo
            [x] check git status
        [x] .gitattributes
            "*.avi binary"
            https://git-scm.com/book/en/v2/Customizing-Git-Git-Attributes#_binary_files
        [x] save data/ in grandparent directory
        [x] add the one discovered file to data folder
        [x] build .gitattributes w/ all media extensions: .avi .png .jpg .mp4 .h264
        [x] remove current data/ contents from git parent
        [x] organize data/ delete most
        [x] add data repo/
        [x] add data-repo-gitignore
        [x] assume unchanged the sub-repo readme from this repo
        [x] verify git status in two directories works as expected

        notes:
            suggest "git submodules"
            https://stackoverflow.com/questions/1811730/how-do-i-work-with-a-git-repository-within-another-repository



    [ ] fourth action
        [ ] displayclass test for simulated selectRay / selectCircle
        
        [ ] then maybe you can refactor display.show() for orientation handling
            the main issue appears to be that coordConversion routines need
            the class data in the non-rotated form to convert coords; that causes
            us to have to rotate back and forth each time

11/7

    Vid Processing + Other notes:
        - guirecord has "ball_color": "green", at top level, 
          guiview thinks it should be in details:{}
        - git update-index --assume-unchanged notes/guirecord.jsonc
          (for all .json's)
        - why is 640 resolution messed up on guirecord? and sys camera?
        - how to get MS IR camera on surfacebook?
        - november bounce data dimensions:
            camera 1 ft from back wall
            table is 4 ft long
            camera is 3 ft above table
            throwing position 8 ft from camera (0.5 feet from table begin)
            table end is 3.5 feet from camera in z-distance (but also 3 ft below)
        - for output1 - output6, out3 and out4 have no timelog (why?)
            are they the longest?
            did I just exit from gui to quick?

        [x] calc speed
            ~1.5 mph towards the camera
            [ ] build calc speed function

        proc conventions:
            frame_type: 
                "mask" - just background, no ball
                "mask_agent" - background + person, no ball
                "calibration" - ball is near and still
                "setup" - ball + person is moving near to far
                "throw" - ball is in motion
            (for output1)
            objEnum:
                "0": ball
                "1": ball in throw at high point

        Ergonomics:
            very annoying to go back and forth focus between windows
                -> we can pass waitkey vals from opencv to tkinter
                    no need for even a select statement, just pass the byte/decoded val
                    from display.show() -> guiInterface() -> guiHeader e.g. cmd_sw_initVid()
            need a new way to draw rays - one click
            need a better key then enter for selectRoi confirm
            arrows to move zoom window would be nice
                or maybe scroll wheel on mouse or


        Other thoughts:
            - a better way to build these vids is bouncing against 
              the wall and having it come back, and re-throwing. also, you
              can edit out the catching / throwing.
            - use git diff --no-index file.metalog file2.metalog
              (but it doesn't highlight all diffs, how to do?)
                --word-diff [nope]
                --find-renames

        Tasks:
            [ ] a good output1
                [x] frame_types
                [x] ball_is_present
                [ ] full scoring
            [ ] a good output3
                [x] orienetation
                [ ] obj0 and 1 for green and orange ball respectively
                [ ] bounce scoring

        Bugs Found:
            [x] orientation on score_display does not go profile
            [x] select ray in score_display with 90-orientation is fubar
            [x] after awhile, Writevid=ON does not work; maybe on selection-controls reset
                 - for output3, at frame361
                    [x] let's try w/o starting at exact beginning: same
            [ ] orientation does not get set in guirecord / guiview pipeline
                [ ] add to guiview.jsonc ?

        


    afternoon todos:
    [ ] process data
        [ ] set orientation
        [ ] validate other inputs
        [ ] erase end of video
        [ ] build quick vids of just bounce (after they've been scored)
        [ ] add scores
            [ ] basic - ball circles
            [ ] basic - bounce rays
            [ ] add training scores; how?
            [ ] add training masks; how?


    [x] utils.ImgDiff should handle diff pixel number types:
    [x] get test_Scoring_obj_enum_6 running
    [x] if block
    [x] annotate obj enum test
    [x] selectRoi test for zoom
        [ ] test on diff framesize
        [ ] test mod0
    [ ] can we test selectRoi-in-zoom for a score?
        no we'll need to add stubs into the class itself: ControlDisplay line708: override rect
        [ ] test that tracker draws from main show up in score_display and vice-versa
    

    Collect some deferred tasks here:
        [ ] draw tracking onto score_display  (11/6)
        [ ] destroy windowThree from gui   (11/7)
            when you set track=ON, and you bring up score_display, 
            but then turn track=OFF, you're stuck with an n/a-frame 
        [ ] refactoring guiview_test      (11/1)
        [ ] draw_ray( bOffSetRay)         (10/30)
        [ ] TODO-SS in trackFactory - not truly multi-object yet   (10/30)
        [ ] orientation resize of score_display: should be by height=320  (?)
        [ ] can't add a param with framenote-override           (10/30)
        [ ] frame_sync using camera pointed at screen
        [ ] investigate "#Bug- does this need rotate_bounds as below?"  (10/24)
        [x] investigate "#?# self.frame = imutils.rotate_bound(self.frame, - self.orientation)"  (10/24)
        [ ] investigate "#BUG-check if zoomRect is in bounds in new video"  (10/24)
        [ ] All those imports needed in guiview?  (10/23)

        Other thoughts:
            - what other tests exist besides in test/ folder? can't we just run
                >pytest -vv  in test/ for run all

                + vidwriter / miscutils have tests
                + dataschemas has tests

            - profile startup time to reduce it (+ tests run faster?)

            - build a ["realtime"] timeout tracking fucntion wrapper:
              tracking processes untill time's up; returns best result
              available at that time: e.g. 27 different thresholds

            - h264 encoding will change if frames are skipped (?)
        
        Collect deferred tests here:

            [ ] orientation
            [ ] guirecord <-> guiview
                [ ] record -> benchmark -> view (tests encoding/decoding codec)
                [ ] create synthetic benchmark: np.zeros(x,x,x)+cv2.draw and then load
            [ ] writeFrame bDuplicate overriding frameData w/w/o score
            [ ] modulo zero stuff
            [ ] view hand-drawn selection
            [ ] view zoomFrame
                [ ] track-on/off; score-on/off
            [ ] semi-loaded vs preloaded
            [ ] --dir run with different sizes, orientations, scores yes/no, zooms on/off
            [ ] output video, especially towards end, e.g. w/ frameFact._validCurrentFrame()
            [ ] add score to frames in already proc'd video

    Main Tasks outstanding:

        [ ] evaluation (10/16)
        [ ] ipython-interproc (10/16)
        [ ] apply iterThreshB
        [ ] documentation of guiview
        [ ] refactor vidwriter /miscutils
        [ ] single test command / test heirarchy
            

11/6

    [x] more tests
        [x] show score_display with w/ only tracking
        [~] draw tracking onto score_display
        [x] modulo zero on show_tracking
            [x] get data
        [x] new pattern with if statements

    [ ] build data
        [ ] 3 bounce vids
            [ ] background
            [ ] agent no ball
            [ ] bounce

    [ ] post data
        [ ] repo inside repo, test with dummy repo

    [ ] process data
        [ ] add some rays for bounce

    [ ] add documentation
        [ ] add repo
        [ ] add readme
        [ ] jupyter notebooks for:
            [ ] guiview
            [ ] guirecord
            [ ] timelog
            [ ] adaptive thresh

11/5

    [x] tracking is broken:
        [x] figure out how to use git to revert to a working time
            git checkout  5c40a25ab2046125d6ded4c1b30d0bf675f1f60b
            (git checkkout master reverts this)
        [x] debug it:
            demo-proc/output4.avi -> breaks w/ only --track
            -> works with --track and --showscoring
        [x] it doesn't error, but it doesn't show score_display either:
            ->need to separate window three logic from --showscoring (which should be 
                just for displaying metalog-score data)
        [x] add test to cement it

    [x] better verifyAction

    writing tests for stockfish
    http://tests.stockfishchess.org/tests

11/2
    [x] test_show_score_on_off_1() basic run pass
    [~] then do with arg
    [x] then re-run with if-blocks

    [x] this could get annoying if we need to constantly update benchmark in tests
        -> need an automated re-bench function for each test

    [x] next commit
        [x] pattern dif folder
        [x] collect 2nd test data
        [x] 2nd test
        [x] rebench pattern
            [x] test rebench

    
    [x] verify in ipython theres actual diffs b/w test images: no, so is staging func wrong?
    [x] why is viz_diff showing diffs wrong?
    
    [x] why does test_show_scoring not work? on which alleged asserts?
        [x] need to re-collect the data all based off 1-video

    notes:
        good np primer
        https://realpython.com/numpy-array-programming/

        [ ] why doesn't pytest enter __name__ == "__main__"

11/1

    [ ] guiview_test - split into staging module
        [ ] this allows us to develop staging routine better
        [ ] better develop file delete routines
        [ ] better develop reading the test data file as function
        [ ] asserts in tests should not be wrapped in try
    [x] controldisplay_test -> split
        [x] controldisplay_staging
        [x] helperfunctions


10/31

    [x] build test pattern for display, framefactory, etc
        [x] display pattern
            [ ] _test_get_frame, other test helper methods
        [x] tests:
            [x] view scoring
                [x] main_display
                [x] score_display
            [~] view hand-drawn selection
            [~] view zoomFrame
            [~] allowduplicates=off and try to add duplicates; try with back-and-forth
        [x] sections for display testing: Class-level tests, Method-level tests

    [~] single command to run all the tests
        [~] see chess workspace, but not the .bat

    [~] finally, refactor vidwriter and miscutils

    [~] experimental vids

10/30

    [x] reset display.outputScore
        [x] add this to test_write_score
    [x] gui. annotate obj: reverse radio labels
    [x] add test write_adv_score
        [x] and added write_score details
    [x] add test custom_framelog_1
        [x] document the git diff for documentation in guiview_test
            git diff 27b57b3 44d6aa7
    [~] add test custom_framelog_2
        custom-framelog does not work on proc'd vids?
            -> b/c you need to overwrite in framenote.jsonc
    [x] add test edit_framenote:
        [x] try with param edit while also new scoring
        [x] make sure old scoring does not get lost
        [~] try with back-and-forth, are originals note edits preserved? no they are not
    [x] add test edit_framenote_override
        [x] try with back and forth
        [x] try with scoring, is it overwritten, is it preserved?


    Thinking of more tests:
        [x] orientation, selectZoom selectROI on these
        [x] resizing zoomFrame / scoreFrame
        [x] preload vs semiload

    Misc Features:
        [~] framenote-override doesn't ADD to framenote (only overwrites). Change this?
                see: guiview_test:test_override_framenote

    List of other bugs, features:
        [~] draw_ray( bOffSetRay)
        [~] TODO-SS in trackFactory - not truly multi-object yet
        [ ] trackAlgo: trackLargestDiffInDesignatedRect
                a bounce can be found via largest diff, but sometimes background diffs
                will be larger, therefore we can rule those out with
                a hand-drawn rect deignates the areas where the bounce will occur,
                this can be encoded as say obj4?

10/29

    [x] display.circleTrack -> trackScore
    [x] trackFactory: multi object tracking

    [x] build a new test
    [x] add display to all stubs and all mocks in guiview
    [x] get a recipe for debug where you can write to file a display window's state
        in outputConsole: from modules.TestHelpers import outputDisplayState(args)
        then call outputDisplayState or something
        or just write it as a method in Display class
        -> use this for matching display state



10/26

    [x] annotate enums
        [x] get color correct on display.outputObjs
    [x] trackFactory scoreSchema
        [x] "#TODO-SS" is still commented here
    [x] does deleting __init__ in test/ matter? to debug? or pytest?
    [x] build some tests
    [x] investigate the bugs
    [x] consolidate test runs with a script


10/25
    [x] cli for obj to show in score_display
        [x] does this throw an error if object is wrong?
    [~] vertical score_display is too large
        [x] test this
        [ ] fix this
    [x] need to reset display.outputScore so we 
        [x] a) don't rewrite an old score onto new frame?
        [x] b) don't have a cluttered view
    [~] file debug import/step-into from root/test/
        [~] reproduce: CAN'T
            KEY: it only works when you don't call with erroneous arg's
    [x] file output-panel pop-up bug
        [x] reproduce in blank workspace
        [ ] file the bug

    Research on VSCode issues

        import cv2
        https://stackoverflow.com/questions/50612169/pylint-not-recognizing-cv2-members/51916065#51916065
        https://github.com/Microsoft/vscode-python/issues/2879
        https://github.com/skvark/opencv-python/issues/131

        popping up output panel
        https://github.com/Microsoft/vscode-python/issues/2262
        https://github.com/Microsoft/vscode-python/issues/2412
        https://github.com/MicrosoftDocs/intellicode/issues/12
        https://github.com/Microsoft/vscode-python/issues/2017
            tells you how to: installl a dev build of the extension
        https://github.com/MicrosoftDocs/intellicode/issues/9
            suggested fix: "vsintellicode.python.completionsEnabled": false
        https://github.com/angular/vscode-ng-language-service/issues/187
            related appraently

            How to reproduce:
                in scratch/ create a new folder: demo_popup/
                create a file called demo.py in demo_popup/
                open demo.py:
                    import os, sys
                    def foo():
                        x=1
                        return x
                save file
                do to another file in editor, but leave demo.py oepn as a tab
                go into explore, close the exapnded demo_popup/ folder
                then delte that folder
                should cause:
                [Error - 6:30:21 PM] One or more errors occurred. (failed to parse file file:///c:/Users/wsutt/Desktop/files/ppd/ppd/scratch/repro_popup/demo.py)


10/24

    [x] finish display.show() roi Zoom
    [x] display.drawOntoPane() add coordRelative switch statement
    [~] selectROI for ray should be selectFromCenter = True (4 places to ammend code in display.show())
    [x] remove Legacy-SS
    [x] scoreRect for rays, scoreRect for dif objEnum's
    [ ] build new demo-proc's with scoringschema in their metalog

    [~] investigate "#Bug- does this need rotate_bounds as below?"
    [~] investigate "#?# self.frame = imutils.rotate_bound(self.frame, - self.orientation)"
    [~] investigate "#BUG-check if zoomRect is in bounds in new video"

    [x] annotate enums to obj's

    Notes:
        display.roiRect holds display.outputScore (hand drawn markers)
        display.roiRectScoring holds displau.inputScore (read from notes)

10/23

    [x] Enumerate Tests:
        
        Display:
            types of tests / questions:
                - Compare image ANSWER to method result
                    for drawing, zooming, cropping, etc
                - How to avoid selectRoi?

            test instances:
                [~] Test zoom on rotation, is zoomFrame correct?
                [~] draw_ray w/w/o bOffset
        
        guirecord <-> guiview
        [~] record -> benchmark -> view (tests encoding/decoding codec)
        [~] create synthetic benchmark: np.zeros(x,x,x)+cv2.draw and then load

        [~] writeFrame bDuplicate overriding frameData w/w/o score
        [x] scoring output
            [x] just from display
            [x] just from notes
            [x] a merge of notes and display (update/add)
        [~] modulo zero stuff


    [~] Misc Thoughts:
        [~] All those imports needed in guiview?
        [~] h264 encoding will change if frames are skipped (?)
        [~] sync framerate by pointing webcam at screen
        [~] build a ["realtime"] timeout tracking fucntion wrapper:
            tracking processes untill time's up; returns best result
            available at that time: e.g. 27 different thresholds
        [~] how to test roiSelect()?
            in stub set a param on Display .bTesting
        [~] profile startup time to reduce it (+ tests run faster?)

    [ ] VScode/misc:
        [~] indentation in controlflow_test.py is wrong; fix
            maybe b/c copy from notepad a json?
        [x] can't step into import for debug controlflow_test.py
            a cwd thing? no: we need to copy test function to root level to get debug
        [ ] how to assign hotkeys to debug tasks?
            [ ] launch a particular file
            [ ] launch with
            [ ] assign breakpoints before running debug
            [ ] clear all breakpoints


10/22

    [x] ScoreSchema

        Checkpoints:
        [x] Run thru with same functionality
        [ ] Add functionality:
            [x] Draw multiple objects/object-types from inputScore/outputScore
            [x] Assign multiple object/object-types with gui+display
            [x] add scoreSchema to TrackFactory, and then to display.drawTrackers()

        [x] Additional Features:
            [x] assign a particluar obj enum to be zoomed-in in scoreDisplay
                [x] call from cli, parser

        [x] Refactors:
            [x] remove roiRect, roiRectScoring
                keep: scoreRect, zoomRect

        Manual Testing:
            [~] legacyload -output-> ScoreSchema (doesn't work)
            [x] view multiple objects
            [x] view ray object
            [x] draw multiple object
            [x] draw ray object
            [x] view multi and single scores
                [x] add a new score obj
                [x] overwrite existing scores
            [~] view trackers as scoreSchema
        
        Bugs/Refactor:
        [~] output.writeFrame() should have separate arg for framenote scoring
        [x] display.outputScore.reset() called
            [x] needs to only reset other objects (?)
        [x] frameData json can't use int's for dict keys

10/19

    [x] override frame attr:
        [x] build into gui
        [x] run with hard coded edit, mergeDict off
        [x] write mergeDicts
        [x] test mergeDicts
        [x] demo on a proc'd video
            [ ] can this override score delibeartely? inadvertantly?
        [x] add framenote-override.jsonc to .gitignore, guiview.jsonc too

    [ ] write-up workflow to commands.txt
        [ ] initial processing: use guiview.jsonc to write params
        [ ] re-processing: 
            [ ] add hand scoring - new or modified
                [ ] how you ran rewind even after write
                [ ] why to turn "dup's on" to off
            [ ] edit individual frames with framenote.jsonc
                e.g. ball_occluded
            [ ] batch edit params in existing framenote
                e.g. approx_distance
            [ ] how you can run with track=on to see where it fails to find, 
                and score that as a challenge frame
            [ ] deleteframes.py script
    
    [x] deleteframes script
    [~] undo button - remove previous frame written to output in vid, timelog, metalog
        [~] this can be recursive
        [~] retreat a frame on completion
        Notes:
            reset frameFact, timeFact, notesFact, outputFact (?)
            maybe just write a script that deletes frame(s),
            and you can even manually delete timelog, metalog entries

    [x] build scoring schema:
        [x] multi objects per frame
        [x] scoring types: 
        [x] how will this work with gui?
        [x] a ball diff is "two points" beginning and end
        Notes:
            scoring is used for multiple things:
                read-in from metalog
                from display -> metalog
                tracking evaluation
            how does alterframe do both tracking and scoring?
                b/c it's only building scoreRect which is for scoreFrame
                Display: roiRectScoring, circleTrack keep track of points

            we need a schema for score:



10/16

    [x] throw informative messa.ge: when no --dir and no --file 
    [x] cleanup notes / refresh concepts / fix tiny bugs
    [x] manually test tracking_params edit
        output4, frame154 fails to track, alter param: 
        "thresh_hi": [74, 255, 255]  (from 64,255,255) and it finds ball
    [x] manually try changing a framenote on a proc'd video
        works for changing a note-attr, but not scoring

    [ ] Still lack features to alter framenotes on proc'd vid:
        [x] Can't easily batch alter a param, need to do indv each frame
        [x] Can't change score to new params with gui-roi
        [ ] Can't apply track as score
            [ ] add score_type: 'track-score'
        [x] Need multiple scores for multi-object tracking
        [~] An undo button for last frame proc
            [~] recursively this is just remove last frame
        [x] We writeframes even when they're duplicates with Writeframe-On;
            don't do this b/c we want to forward reverse while proc-ing
        [x] Need to advance on writeFrame / writeScore

        TODO:
            [x] reorder gui
            [x] gui don't write duplicate frames; default on
                [x] not correct: we still want to overwrite a frame
                [x] gui -> main
                [~] still not quite correct: can't overwrite a framenote attr
                    when that framenote has a score
            [x] refactor outputFact to setCmd()
            [x] advance on writeFrame
            [~] blink on press of write frame
            [ ] add button: writef + track as score
                [ ] add functionality
            [x] add button: overwrite the param(s) for all
                [x] add functionality
                [x] how to do nested json update into nested dict
            

    [ ] evaluation function
        [ ] error function - diff (x,y); diff radius
            [ ] diff color - 95% pixels in some range
        [ ] TP/FP/TN/FN - for whole video

    [ ] ipython output
        [ ] current frame img
        [ ] current frame notes
        [ ] zoom frame (coords and img)
        [ ] tracker params
        [ ] tracker stored data
        [ ] tracker previous position
        [ ] tracker diff

    [ ] output various transforms of frame onto window3, etc

    [ ] apply iterThreshB

    Other possible bugs to be investigates:
    
        FrameFactory.getFrameSize doesn't use frameOrig for shape:
            is this causing output video to have wrong orientation?


10/10

    [x] Fix zoom_display logic
        we want to be able to do zoom in the course of --track and --showscore

        [x] isolate the problems:

        [x] fix with refactor
            [x] hello windowThree
            [x] zoomOff should apply to windowThree; right now it disables winTwo
                [x] refactor zoomOff -> scoreOff
                [~] refactor alterZoomFrame -> alterSubFrames

        [x] manually test for regressions

    [ ] Add ipython module
        [ ] sockets module, just a server?

    [ ] .tracklog output

    [ ] evaluation 

    [ ] build more videos
        [ ] blank background / with person-no-ball
        [ ] with a bounce

    [ ] cython for circle_pix

10/9

    [ ] trackTimer
        [ ] output
        [x] to gui

    [x] trackParams
        [x] modularized
        [x] read/write from json
        [x] reset default
    

10/7

    lots of copy()'s occur throughout trackFrame pipeline:
        can these be turned off for optimal track perf?
        what do we lose by eliminating them? e.g. writeout ability?

10/6 

    [ ] build filter_pix_circle in ipython
        [x] good demo cell on generated image
        [ ] demo on frame0 of output4 with score rect
        [~] build sruare_inside_circle
        [x] convert pix_list to be accepted by iterThreshA img arg

    [x] add filter_pix_circle to TrackFactory
        [x] convert pix_list to be accepted by iterThreshA img arg

    [ ] Add same img processing (as are applied in track) to training images
        before running iterThreshA

10/5

    [x] add a --startplay for debugging

    [ ] we can pre-train tracker and write output to .tracklog

    bugs:
        [x] output7.avi - frame 220 has a a zoom_img with width=0, breaks
        [x] output7.avi - frame 223, can't retreat frame

10/3 - 10/5

    [ ] build training video on output8.avi

    [ ] add tracking algo module

        [x] basic tracking
            [x] show in main window
            [x] show in zoom window
                [ ] show last zoomWindow when track fails
            [x] add cli option
            [x] add gui element
            [x] work with rotation
            [x] work with different size images
            [ ] handle obviously false-positive, e.g. whole screen
            [ ] pause on failed track
        
        [x] add training agenda

        [x] add iterThreshA

        [x] add a parameters module separate from code
        [ ] add a way to view/edit params: maybe by file, 
            [ ] then a reset-to-default button on gui
            [ ] then a refresh tracking on gui
        
        [ ] comparison module
            [ ] two trackers, display both results
                [ ] zoom_display enclosing for both

        [ ] more videos
            [ ] better organized
            [ ] orange ball

        [x] Need to divorce tracking/scoring display from zoomRect

    [ ] bugs discovered
        [x] zoom_display freezes after video recycles
        [x] show zoom_display previous when no track found 
            ("ball is likely near there, you'll want to investigate")
        [x] output6.avi fails on getFrame() and it's semiloaded
        [x] can't do a separate zoom with trackOn, maybe make it a separate display? 
        
          

    [x] add a way to overwrite frame note attribute(s) in batch:
        in notes/framenoteoveride.json

    [ ] add tests for guiview / Display

        [ ] rotate
        [ ] crop
        [ ] modulo zero
        [ ] overwrite frameNote
        [ ] writeout scoring

    [ ] build additional training videos:
        [ ] Lossless
        [ ] Mask for background
        [ ] process the additional video

10/2

    [x] fix --dir with multiple orientations

    [~] add frames to existing video (not possible AFAIK)

    [x] compression radio button
        [x] contorls vidwriter
        [x] defaults to metalog compression value fourcc_enum

    [x] dont erase framenotes when video re-cycles

    [x] dir is broken on data/proc/demo-proc folder
    
    [x] write processing-compressiontype in proc-data for output metalog

    [x] semi-preload
        [x] default to this when preloaded and file size is too large
        [x] demonstrate with output8

    [x] bug in semiloaded: starts at last frame loaded

    [x] keypress basics

    [x] overwrite frame note template
    


10/1

    [x] run tests
    [x] Bug Fix & Review roi/zoom
        [x] review select roi
            [x] draw in main vs draw in zoom
            [x] draw in mod0 vs draw non-mod0
            [x] at 1280
    [x] getScore -> metalog json
        [x] gui elements
        [x] reset frameScoring or in Display
    
    [x] build two training videos

    [x] show on replay
        [~] gui element
        [x] cli option --showscoring
        [x] add delay for score or train
            [x] different for file vs dir
        [x] follow with zoom cam
        [x] different color blue to show pre-scored
        [x] how to overwrite / compare scorings?
            [x] "add additional non-scored as scored"
                [x] load to framesDataExisting
        [x] does log of a processed
        

    [ ] other todos
        [ ] 
    [ ] other tests

9/30

    [x] Can't do another zoomSelect that's small:
    
            zoom_img  = resize_img(zoom_img, True, (widthZoom, heightZoom))
                ...
            TypeError: integer argument expected, got float

9/26

    [x] write up commands.txt
        [x] using tail with proc's .metalog
        [x] using --framelog for custom .jsonc

    [x] intellisense for cv2

        hasn't worked since upgraded pip install opencv-contrib-python
        ok, so from cv2 import * gets it to work

        [ ] file bug for this

        [ ] file bug for python.analysis pop-up, or fix

        [ ] how to turn off inline-breakpoint displays: margin glpyhs on?

    [x] paneFactory
        
        [x] mimic existing function, e.g.  output7.avi

        [x] add selectROI
        
            [x] resize during selectROI bug
                maybe b/c it's resize to wrong dimensions?
                http://answers.opencv.org/question/84985/resizing-the-output-window-of-imshow-function/
                https://stackoverflow.com/questions/47524734/selecting-roi-in-auto-resized-window

        [x] zoom window

            [x] need "mod" / "%" padding on zoom frame, so zoom box will convert to whole integer
                coords in main img

            [x] need to make a circle within bounding box? or only afterwards?
                [ ] how to cut img pixels out of a circle?

9/25

    [ ] notes factory
        [ ] notesFactory.getOrientation -> paneFactory
        [ ] notesFactory.getCompression -> guiInterface(g.CompressionType)
            (which then flows thru to outputFactory)
        [ ] notesFactory filters DirectoryFactory for notes attributes
        [x] add tests
    [x] guiveiw.jsonc
    [x] per frame json
    [ ] guiview output finish.
        [ ] add tests
    [ ] pane Factory
        [ ] two extra windows
        [ ] one extra large window
        [ ] sub window image zoom
        [ ] bbox on subimage <- bbox_main
            [ ] conversion coord's back to main
        [ ] img_rotate based on orientation
        [ ] gui.update(scoringFeatures)

    need new opencv to get selectROI:
    
    https://stackoverflow.com/questions/42387322/how-to-add-tracker-in-opencv-python-2-7
    https://pypi.org/project/opencv-contrib-python/3.3.0.10/
    cv2.__version__ = '3.2.0'
    Lib/site-packages/cv2.pyd (modified 12/23/2016)
    opencv folder in downloads is modified 5/6/2017

    upgrading from pip 9.0.1 to 18.0

    C:\Users\wsutt\Desktop\files\ppd\ppd>
    C:\Users\wsutt\Desktop\files\ppd\ppd>pip install opencv-contrib-python==3.2.0.8
    Collecting opencv-contrib-python==3.2.0.8
    Downloading https://files.pythonhosted.org/packages/f9/01/7c80c13a9b8de8c15da5568a90bcc7a33ce345651613e9af14d7eb23d741/opencv_contrib_python-3.2.0.8-cp27-cp27m-win32.whl (24.4MB)
        100% |UUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUU| 24.4MB 605kB/s
    Requirement already satisfied: numpy>=1.11.1 in c:\python27\lib\site-packages (from opencv-contrib-python==3.2.0.8) (1.14.5+mkl)
    Installing collected packages: opencv-contrib-python
    Successfully installed opencv-contrib-python-3.2.0.8

    now it lives in it's own folder: site-packages/cv2/cv2.pyd


9/24

    [x] fix write_time_bad test: need to delete more than just .txt in test setup
    [x] file bug report on pause/continue for basic()
        #https://github.com/Microsoft/ptvsd/issues/837

9/23

    [x] refactory directoryFactory to outputFactory
    [x] add snap vid write button
    [ ] add config to the button; green if written; reset if new frame
    [ ] add [separate] button to snap-write-frame and hand-scored data
    [ ] add writeframe-writescoredata-and-advance button/keypress
    [x] need way to view frame notes as we step-thru (tail -f outputX.metalog)
    [ ] add output compression-type to gui and OutputFactory
    [ ] add output as image option

    [ ] add tests for output functionality
        [x] does it write; size > x
        [x] can it advance without writing?
        [ ] does it match a premade vid? only certain frames, only certain contguous frame regions
        [x] do two outputs
        [x] non-default framesize
        [x] snapWriteFrame
        [x] test log output
        [x] test log output when no good log exists
        [x] test frame json
        [ ] test time it takes to write new json metalog each time

    [x] log outputs:
        [x] timelog
        [x] import notes from metalog
        [x] frame json onto metalog
            [x] does it update each time on disk?
                [x] this could be slow? (0.015 secs at most)
            [x] viewable with tail? (yes)

    [ ] open an existing video file, write new frames to it:
        this could be useful for adding additional training frames after experiment
        is originally built

        [ ] use --output for this?
        [ ] or, use gui for that? 
            [ ] with set button, that shows validation

    [ ] remove scratch work from git:
        create mode 100644 demo_sub.py
        create mode 100644 test/demo_dub.py
        create mode 100644 test/demo_subproc.py
        create mode 100644 test/demo_test.py

    [ ] refactor .txt -> .framelog

    [x] build mini-app to test tkinter debug ability
    [ ] look at gui.call_cmd: sv.get() instead of globals,
        see if that helps with debug mini-app multi-thread debug ?
        does it help with space-hold-down-crash?

    [ ] filter vid names, e.g. with or without "proc"




9/22
    
    [ ] Testing guiview updates
        [ ] shorten videos to 25 frames in basic
        [ ] change true_time to reflect a 25 frame vid (cumtime=0.8316 @frame 25)

    [x] Build output feature:
        [x] why isn't VidWriter showing up in directory?
        
    [ ] why does holding down pause-button cause the program to exit without err msg?


9/21

    [x] Testing guiview
        [x] add tests/
        [x] add template for tests on guiview
        [x] add structure of tests to guiview

            since we're running in Popen we need to write out data to tmp file
            or do we? we can do asserts within mock_test() and raise an error and capture in stderr on the console?

        [ ] build a test_timeout function on a thread
        
        [ ] try some of the features in vscode:
            https://code.visualstudio.com/docs/python/unit-testing

        [x] build 12 tests

        [ ] shorten test data: cut the videos down

    [ ] add a preload which checks for memory usage; doesn't overflow
    [ ] add a "streaming" preload, holds N previous frames and pops last one off
        each frameloop

    [x] dot operator for uniqueFn
    [ ] find-project-root function

9/20

    [ ] how to raise opencv warnings to 'except' in python.
        e.g. in frameFactory.setCam throws:
            warning: Error opening file (/build/opencv/modules/videoio/src/cap_ffmpeg_impl.hpp:578)
        do this?
            warnings.filterwarnings('error')
    
    [x] why does pause_on_first_frame opens show frame_i:1 (not 0?)
        [x] and you have t=.03 not(t=0) ?

    [x] frame delay radio above fn on gui

    [x] add slowdown value

    [x] refactor updateGui into by-vid and by-frame


9/19

[x] diagnose gui issues:

    The key was to call build_gui_c() in thread-inheriting class's __init__:
    That way the self of myGui/BuildGuiC can refer to tk elements 
    populated in build_gui_c()

    [x] is this why debug didn't work?

        no, debug (with gui) still fails to recover from pause: both tkinter 
        and opencv windows become unresponsive. And hitting puase again doesn't work

        [ ] Can this debugger handle an arbitrary second thread
        [ ] Can this debugger handle a tkinter second thread with no globals?
            if so, replace globals with queues

        [ ] One way to fix threading is to have main thread call get() from guiInterface
    
    [ ] Implement queue for globals? 
        https://pymotw.com/2/Queue/
    
    here's where the code was lifted:
    https://stackoverflow.com/questions/459083/how-do-you-run-your-own-code-alongside-tkinters-event-loop
    
[x] Refactor:
    [x] remove vars from GlobalsC
    [x] refactor frameFactory updateGui into own class in GuiC
    [x] remove old issues from guiview head-notes
    
[ ] Refactor - rename and move vidwriter and miscutils to modules
    [ ] refactor their imports
    [ ] keep tests running

[x] exit opencv window on gui close


[ ] frameDelay bugs:
    [ ] turning on/off pauses vid

[x] finish basic guiview features
    [x] all updateGui   - 10:15
    [x] timeFactory     - 10:45
    [x] extra flags     - 11:00
    [x] extra radio buttons -11:15
    [x] initial gui config
    [x] pause on open
    [x] directoryFactory

[x] add to guiview to commands.txt  -11:15
[ ] write a narrative-log entry     -11:15

[ ] investigate advanced features:
    [ ] shortcut keys tkinter
        [ ] do you need forcus on a particular button for them to register
        [ ] or do we need to register them to opencv window?
    [ ] ROI selection

[ ] build intermediate features on guiview:
    [ ] output image/video
    [ ] read images
        [ ] go into subdirectories

[ ] still need testing on guirecord

[ ] I would like some multi-thread safe data structures, jeez these crashes
    and can't debug; do they fix?

[ ] VScode fixes/updates:
    [ ] get python intellisense msg to stop popping up
        Starting Microsoft Python language server.
        Initializing for C:\Python27\python.exe
        [Error - 2:32:44 PM] Request textDocument/completion failed.
        Message: Start and End must be well ordered
        Code: -32000 
        [object Object]
        object Object]
        [Error - 6:50:34 AM] Request textDocument/completion failed.
        Message: Collection was modified; enumeration operation may not execute.
        Code: -32000 
        [object Object]
    [ ] get a way to do terminal in vscode, and restore 2-panel editor
    [ ] but break points on the margin, not inline

9/17

[x] clean up existing diffs
    [x] add argparse to guirecord
    [x] remove all prints

[x] finish books/sync-frame
    [x] add a demo for sleep schedule #1
    [x] add a demo for sleep schedule #2
    
[x] write up learnings on frame-sync
    [x] and continuing questions

[x] add metadata file
    [x] feed notes in from file

[x] verify logitech camera has same behavior as internalwebcam
[x] verify --funkyread handles sleepschedule differently

[ ] build guiview.py like (fbf2.py)

    [x] check if that basic app structure can be debugged?
        must debug guiview and GuiC separately, 
        run debug config: guiview-main for launch with --nogui

    [ ] gui features
        [ ] get keypress in tkinter
        [ ] zoom in on vid window

    [x] slowdown frames with timelag

    [x] annotate filename on video

    [ ] Note: arrow keys and mouse are used for both scoring (drawing a ground truth circle)
              and for zooming
    
    [ ] separate gui for hand scoring the data
        [ ] create a .scorelog files
            - could be testing whether algo has found the correct obj
            - could be the ground-truth for where the ball is
            - indexed by frame_num
    
    [ ] separate function for drag/select ROI, and processing of that ROI 
        (e.g. create seed thresh-hold)

    [x] --dir to go thru all vids
        [ ] a dir box

    [ ] a settings sqlite db to hold last settings
        [ ] directory
        [ ] zoom settings - ROI

    [ ] do images too

    [x] display on gui
        [x] frame num
        [x] time t=
        [ ] time since last frame

    [ ] display metadata / notes:
         in zmq shell?

[ ] build vidprobe
    [ ] --dir to probe all file in a dir
        [ ] -r recursively probe
    [ ] list
        [ ] num frames
        [ ] running time according to frametimelog
        [ ] file size
        [ ] frame size
        [ ] some description/notes
        [ ] date modified
        [ ] encoding

    filter by criteria:
        [ ] criteria in notes (e.g. ball_present = True)
        [ ] criteria of num_frames, etc

    [ ] works for images too


[ ] Build mock tests for guirecord and timelog

    a test function will call guirecord in a subprocess with cmd args:
    these cli args override initial states of globals at beginning of script
    a warm up period is given to check in body, then cmd_record_on is called
    and at end of num_record_frames you go to exit,
    this creates vid and log files in the test directory of choice
    then you load the data from these files into test function and do:
     - asserts on various stats of the data
     - display/graph the benchmark vs test data in ipython

Note: tracking in guiveiw is really tracker.score(current_frame). 
      But what we're really looking for "seed" / training img before that
      train the image to later i.d. it scoring frame:
      train_img.append(img1)
      train_img.append(img2)
      tracker.train(train_imgs)
       ->
      tracker.score(current_frame)


9/13


[x] need a way to know when recordOn starts in 1-col frame-timing-logs
    [x] add detailed vs simple timelog to gui

[x] going to need a buffer way to record at 1920
    [x] or just hack it with a list of frames
        [x] add hack to gui
        [x] add mem-break to gui (?) rolling create files
        [x] add compression selection to gui

[x] Add noncompression module
    [x] find a noloss codec
    [~] or write the frames as png's
    [x] test this in ipython notebook

[ ] Get an ffmpeg script to convert the vids to correct time

    C:...Downloads\ffmpeg-20171209-f20c8f6-win64-static\bin>ffmpeg -f h264 -i ../../60secondvid.h264  ../../60test.mp4

[ ] Changes to adapt_thresh:
    [ ] allow it to play file-vids
    [ ] do agenda with file-vids
    [ ] do agenda manually with dragging ROI, mousing, etc..

[ ] Get some videos!
    [ ] of long distance range
    [ ] build a notes/schema of vid creates
    [ ] cut the videos to particular images

[ ] Cut the tracking algo out of iter_thresh

[ ] Build a batch processing for all the images

[ ] get cv2 intellisense in vscode


9/12

[x] b_resize to gui
[~] output logfile even without record
[x] setup timelog benchmark directory
[x] record some vids
[ ] build unittests
    [ ] without recording, using existin
    [ ] new rcordings

9/10

[x] Build TimeLog to completion
    [x] add attribute of previewing vs recording to TimeLog
    [x] Build a analysis util for summary stats

[x] Do a demo of analysis:
    [x] framerate under dif framesize
    [x] framerate w/ w/o output
    [x] framerate w/ w/o preview window
    [x] add to commands.txt
    [~] Adding a graphing module

[~] Build some unittests for TimeLog

[~] Make a DB module instead output file



9/6

[x] preview frame on/off
[x] frame size
    [x] frame size on vidwrite
    [x] change frame size in display

[x] cam num
[ ] read from file cam
    [ ] with slowdown b/w frames

[ ] perf testing module
    [ ] difference in fps when preview on/off?
    [ ] difference when putting frame data into holding var instead of out.write
    

8/11

[x] refresh knowledge
[ ] Jumpcut logic
    BUGS:
    [ ] first record as jumpcut throws quasi-crashing error
        notes:
            but jumpcut does work if you do a newfile first
            
    [ ] no way to stop recording jumpcut w/o quitting

        [ ] what if you do new file while record is on?
        [ ] what if you do new file while record is off?


8/6

[ ] Finish jumpcut logic

[ ] Onto...
    [ ] preview window on/off
    [ ] continue record ("jump cuts") or new video after each toggle
    [ ] frame size
    [ ] cam num

8/3

[x] directory text input
    [x] set on init
    [x] read on edit
    [x] color based validation
    [x] change the uniqueFn of the directory

    BUGS:
    hypothesis: can't call from guirecord with gui.myGui.method() -> tk.elem.config()
                can only call config methods from guiB events
    [x] verified and fixed
         

[ ] toggle newFile vs. jumpCut

[ ] see if this can be debbuged via vscode

    
    

8/2

[x] fix writevid1
[x] verify tests, list in commands.txt
    [x] writevid1 line 77-78
    [x] make sure this works from CLI too, not just unit tests
    [x] fix other problems in tests?

[x] hello guirecord.py by 9am

[x] Basic Control Flow
    [x] preview without record
    [x] don't init vidwrite untill record

[x] get a uniquefn textbox with record toggle working by 1020am:
    [x] how to handle preview cam?
    [x] toggle record button
        [x] does the action
        [x] change the visual element of button onState
        [?] multiple actions
    [x] uniqueFn text box
        [x] read from view to model
        [x] set width
        [x] update from model to view
        [x] when to update/re-run
        [ ] how to handle user entered non-uniqueFn, just overwrite?

    BUGS:
    [x] release vidwrite onEndRecord (so we can view it in file explorer)
    [ ] toggling record is overwriting
    [x] need to re-run uniquefn after each toggle?
    [ ] get ext from filename


[ ] Then, add a directory selection gui elem








7/26

[ ] start copying GuiA ton GuiB
    [ ] what's the point of GlobeGui?
    [ ] record button
    [ ] time to record field: default 999
    [ ] preview window on/off
    [ ] continue record ("jump cuts") or new video after each toggle
    [ ] frame size
    [ ] cam num
    [ ] uniqueFN textbox
    [ ] directory textbox
    [ ] codec combobox
    [ ] draw onto frame:
        [ ] currently recording
        [ ] countdown to record-start-time
    
[ ] If we did cProfile we'd know info on processing time
    [ ] do num frames recorded change b/w:
        [ ] gui on/off
        [ ] preview on/off
    [ ] how will cprofile work since we don't have subfunctions?
    [ ] can we read the cam faster with threading?

7/25

[x] do preview/warmup
[x] hello gui
[ ] add a gui

7/24

[x] test input_fn
[x] Build Tests

7/19

[x] bug - Why does writevid1.py at framesize 1280,720 get read by VLC correctly? 
          But then at 1920,1080 it records 2x too fast (Even tho larger?)

    -> Makes sense: since there's only half as many frames logged, and expect to be at 30FPS
        it's playing those frames twice as fast as it should.

    [x] let's count frames on each rez

    >python writevid1.py --showvid --time 5 --savedir data/aug2018/misc/ --framesize 1920,1080 --logfps
    data/aug2018/misc/output6.avi :  9621  kb
    numFrames recorded =  83

    >python writevid1.py --showvid --time 5 --savedir data/aug2018/misc/ --framesize 1280,720 --logfps
    data/aug2018/misc/output7.avi :  7926  kb
    numFrames recorded =  141

    >python writevid1.py --showvid --time 5 --savedir data/aug2018/misc/  --logfps
    data/aug2018/misc/output8.avi :  2491  kb
    numFrames recorded =  143

    [ ] Let's investigate this warning message:
    
        [OpenH264] this = 0x05FE2C70, Warning:bEnableFrameSkip = 0,bitrate can't be controlled for RC_QUALITY_MODE,RC_BITRATE_MODE and RC_TIMESTAMP_MODE without enabling skip frame.

    [ ] Let's look at timestamps on vid via VLC


[ ] Can you get faster processing without doing showvid?
[ ] Can you get faster processing with separate thread?
[ ] Can you get steadier perf after waiting fro a warm-up?
[ ] Can we getter better perf with all frames in memory untill end
    [x] This is 32-bit proc => max_size = 2GB?    """ [MSC v.1500 32 bit (Intel)] on win32 """  
    [ ] calc in-proc size of the frame
    [ ] calc perf time of each component, using time.time and cprofile, timeit


[ ] Might need to add an ffmpeg processing module, e.g. to change frame count, playback fps etc

[ ] Build tests, then exapnd into gui and meta

[ ] Gui's main job, besides start/stop is r/w meta-settings



7/18

[x] basecamp on writevid1, remove cruft

[ ] build some tests for writevid1

[x] build change framesize for writevid1
    [x] toggleframe?
    [x] need to change framesize on VidWrite

[x] camnum arg on writevid1

[ ] put setgain / getcam into camprobe util
    two tests:
     1. setgain prop, see if when you get props it has changed 
     2. take two picture with diff gain and see if one is darker

Other Tasks
[ ] What are commands to check version of opencv, numpy, python, etc
[ ] Separate ReadingFrames from WritingFrames which could make FPS higher (?)




7/17

build PROCESSES!
    well documented
    well tested
    that work together

writevid1.py | fbf2.py  | fdiff1.py

need a summary utility to display file-size, recording-length, frame-size, etc..
    and this should run like 'ls' for all files in directory
need a comparison in size of vid and size of frame between different encoding schemes
need a module for writing a video
need a module for displaying a video

[x] how to eliminate the "windows popup" codec request before writevid1 runs?
    appears to happen for .avi but not h264
    does it happen on mp4?

[ ] need to be able to record different size vids in writevid.py
[ ] set different frame rates
    [ ] verify different frame rates

[ ] get cv2 intellisense in vscode
    [x] it works in ipython
[x] why can't I write out h264 in fdiff1?
    because theres no h264.dll on /data/ path
    [x] try from main ppd/ path - yes, works
    [ ] what happens when you import modules

Modules:
[x] build unique-fn module
[ ] build a set cam params module
[ ] build a show video with time-sleep lag

Scripts:
[ ] build a vid probe util
[ ] build a help function for each script
[ ] build a current_params script which writes current-default-meta-data to meta-data-db on writevid1
[ ] commands.txt becomes a way to run multiple scripts together
[ ] rewrite fbf

Analysises:
[ ] relative size of different codecs
    [ ] for arbitrary videos
    [ ] for vids with just a moving ball
    [ ] half-way between: a person moving and a ball bouncing
    [ ] what does the rpi send best?

Smaller Tasks:
[x] import vidwriter:VidWriter into main scripts
[ ] get all the available codecs by prompt then VidWriter.getcodec()
[ ] variable framesize for videowriter
[x] uniqueFn implement ext=None

[ ] Try Codecs
    [ ] XVID
    [ ] mp4
    [ ] MJPG
    [ ] Lossless

[x] organize video data
[ ] sync data folder with drive

[ ] how to use cursor on opencv windows?
    [ ] to select a region, see fast-tracking video example
    [ ] to select a region to zoom

[x] try out test_vid_sizes
For all three cameras (laptop 1 + 2) & webcam (c920):
(640, 480)   True
(1280, 720)   True
(1280, 960)   False
(1920, 1080)   True

Idea: _CVT_ the fdiff frames to a color close to the ball, then do a diff
        which will let us maximize the diff for only the ball
  





7/9

I need to build a list of tasks and start executing:
I want an example of laptop/pi picture working
then I really want to test that optical flow thing
This seems helpful: fast tracking in opencv
    https://www.youtube.com/watch?v=X6rPdRZzgjg
    https://github.com/osmaa/pinymotion/blob/master/pinymotion.py

Questions:
how to play .avi's?
how to play h264's?
how to send h264/other-format over stream?




General Thoughts:
This is a process problem, not a beautiful code problem. Since we don't know how the solution looks at the beginning, we need the processes to iterate there.

Remember, the idea was to use two cameras for mo-cap: one for noticing diffs quickly, the other for precisely locating ball


Worskapce Discoveries:
notes/commands.txt has pi-server instructions
notes/notes-dec.txt has concise and useful info


7/7

build high-level todos
re-run and record main commands

High Level Todos:

Need to build a script that saves videos
Need to create a variety of videos:
    very distant ball
    bouncing ball, 
        different backgrounds
        different fps
    different cameras
    different cam params
Need to create meta data for each recording
Need to build library of videos and frames
A way to run algos onto all test-vids
Need to create unit tests for functionality?
Build a sqlite db that stores settings for thresh levels
    and track-algo params
Do a bunch of exploratory analysis beyond simple-thresh
    optical flow
    edge detection
    circle recognition
Rethink the approach to bounding box: create a circle and add
the area not included as color to absorb
"Find some positive": expand the thresh range to search for a 
small ball

Common Commands:
how to connect ot rpi over socket?
what flags make a difference on adaptive_thresh
fbf works? is valuable tho?


12/17

x Picamera working without errors
doesnt timeout here:
    Traceback (most recent call last):
    File "adaptive_thresh.py", line 314, in <module>
        main()
    File "adaptive_thresh.py", line 126, in main
        vc = initCam('pi_cam')
    File "C:\Users\wsutt\Desktop\files\ppd\ppd\modules\Camera.py", line 51, in initCam
        return MyPiCamera()
    File "C:\Users\wsutt\Desktop\files\ppd\ppd\modules\Camera.py", line 18, in __init__
        self.connection = self.server_socket.accept()[0].makefile('rb')
    File "C:\Python27\lib\socket.py", line 206, in accept
        sock, addr = self._sock.accept()
    KeyboardInterrupt
Picamera init cmd arg
Picamera set params
Picamera rotate controls
Picamera as a secondary camera

print FPS to cmdline



12/16

check the individual times of streaming. Can you read more quickly right at the beginning?

dont print out, does that save time?

x can we read faster if we skip processing? kinda not

different thread to read and record?

Add the streaming to adaptive_thresh


12/16

x Create a git basecamp

x Find a way to ftp or scp from laptop -> rpi
    got filezilla 3.29
    sitemanager:
        use port 22
        saved as pi_wifi_1

x Verfiy camera.capture_sequence speed
x    extend to verify the final image is saved
x    verfied at 29.5 fps, using video port, 640

x Can you  get a faster capture_sequence ?
x    by altering fps and exposure? YES but FOV is limited.
        at request 60fps, we get 58
            Captured 120 images at 58.63fps
            10.0.0.123 - - [16/Dec/2017 19:15:42] "GET /take6/ HTTP/1.1" 200 -

     by threading?

x add an argparse for client

x Verfiy Ethernet throughput speed

Build a bach script for ops
    workon cv
    export FLASK_APP=camera-server.py
    flask run --host=0.0.0.0

Build simple recipes and benchmarks collection
    send an already saved image
        wifi vs ethernet
    send a bunch of tiny images
        wifi vs ethernet
    
    basic responses
        send text
        send img
        send a stream
        send data in the url

    build a global Camera class in camera-server.py
        configure requests
        and capture requests

Find a way to do X11 on pi


12/12
https://stackoverflow.com/questions/29065624/using-with-inside-a-thread-in-python-picamera-opencv

12/10

why doesnt iterThreshA change for RGB on set_thresh decrease? But HSV does?

try simple flask on rpi, record time
    local server time
    ethernet connected time
    compare against SimpleHTTPServer

how to get flask threaded=True to run?


12/8

x add options for camera capture size
x add filecam
x add outer loop to reset camera
x dont mirror camera_usb=1
record a video
write a small utility that calculates fps from time in video


12/2

x find all camera sizes
x hello world on the pi-camera

12/1

working well at 10 feet
1280p
rgb: (orange ball) [  0  96 192] [ 88 232 255]
blur 11, repair 2

green sharpie:  [ 15 106  86] [ 81 171 148]

increasing thresh_pct > 0.95 helps with motion blur

11/24

x agenda nextstep triggers them all - sw_ not reset?, or gui firing too much?
x test and debug agenda reset
x it does create a new folder in write_dir for each agenda
x does it reset for a new color ball? yes.
x it takes the first img after reset from the last old_pos for tracking_frame
x two pictures from initial center_tracking frame, make it one
x set the gui from a output_rgb_set
x extend to hsv
x refactor globeGui
x refactor gui to eliminate extraneous
x print output as values
x little wider display
x update gui-hsv-output after runIterThreshA
x verify that thresh_pct is different
x better printout for solves
x less verbose
x have outcome stats display
x Proof-of-Concept: do iterThresh with 1 training image, then multiple training images
x better perf? - yes
x at least wider thresh? -yes
x call iterThreshB from gui
x tracking params from gui
x agenda.combine_threshes: transformA(img.copy(), blur = 1, b_hsv = True)

iterThreshB outputs initthresh? Not exactly but still seems sketchy

Show-How-Far-You-Can-See-Ball
x tracking success displayed to output
x display shows wide circle around putative ball
also diagnose iterThreshB on 
also display radius and num_of_cnts_found on display

Most important:

    Resize

    File_Cam


Can do an iterthreshB agenda creating a mask where there are FP's?

do the tracking without resize
find a way to know if it sees anything and what width?
    "is it seeing the ball way out there? What's the furthest it can see the ball?"




x take off delay for startup
x preview-display horizontal mirroring
x display other types of images  -> 2x cv windows?
x hist for the rect
x background histos
x flip transformed image
x params for adapt thresh
x options
x proc histo only onshow
x change frame and get histo
x show background_histos
x adaptive y_lim
x why doesnt the hard coded y_hi change for 6th plot?
x make subplot 2 by 3 not 1 by 6
x make a reset of current_tracking_frame force a resize in histos
x display a transform window
x organize function to imports
x pull out np.histogram from updating function
x large blocks to functions
x ptions to a function
x global modify from options-func
x display transform and mask as smaller
x need to get globals set in Options
x pause on a picture for searching for thresh_params
x write-out pics
x write rect non-transform
x write all to same dir
x write other pics
x frame isnt copied?  

tranform and regular img track

do a np.histo work on n
threshold pct array
expand and contract threshold

waitkey switch statement
write out video
print in raw_input with carriage return
histo labeled hsv for hsv histos
options for backghisto
do a thresh on each histo
display info in histo title

adapt_thresh for saved videos
eval in options
3rd rgb-plot-pane rect before vs. current "background before ball was there"
search_thresh
do agenda
zeromq messaging for log
run on pi

#Questions

Q does a switch statement make waitkey more responsive?
Q resolve ugly globals code
Q organize imports to and classes

> python adaptive_thresh.py --showbackghisto --showhisto

> set_thresh 80 100 100 130 200 200
150 130 90 200 210 200
100 130 90 200 210 200
0 130 90 100 210 200

speed up histo proc:
    keep it all numpy
    only when updating
    create tests, test data


#Questions

Locate / Track 
    -  how many shapes are there?

#Notes

why current LiveHist is bad
    matplotlib window can't be moved after startup
    makes peview-display jittery
        could this be solved with threading?
    makes cvWaitkeys not responsive

    solution is an html/js app in browser with http interface

