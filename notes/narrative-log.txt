9/15

even a .001 float drift per frame -> 1.0 seconds after 1,000 frames!

"just assume the frame was grabbed at the end of last frames read()

Need to do 2 days of this:
https://www.pyimagesearch.com/2018/07/30/opencv-object-tracking/


We're finding that framelog times dont correspond to the actual time between frames: it's only the next frame that has the delay. Check out grab/retrieve vs read() on videocapture class:
https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html
https://docs.opencv.org/3.2.0/d8/dfe/classcv_1_1VideoCapture.html

This guys sees old frames in buffers, needs to path opencv directly
https://01.org/developerjourney/problems-camera-lag

    Here's the source for patches:
    https://github.com/jketreno/robot/tree/master/patches

People familiar with the problem
http://answers.opencv.org/question/29957/highguivideocapture-buffer-introducing-lag/

He says call grab five times
https://stackoverflow.com/questions/41412057/get-most-recent-frame-from-webcam

    it appears grab 5x or 11x doesn't work
    but retrieve 5x does work


It appears as soon as read() is called on 4th frame, another image is grabbed on camera
so when we go to 5th frame, after sleep we retrieve that image so it doesn't appear delayed.

Looking at frametime plots in analyze-frame-time.ipynb:
    cam.read() is deliberately slowing down the call time as it can go to 1 millisec 
    when the inter-frame-processing overhead forces it to.
    
    That's roughly 2/3 of processing time be used for dilly-dallying, if you needed more proc time, seek to put this on another thread or something.
    
It's still not clear if long start-end- intervals are reading camera's CCD at start or end of that time. But working hypothesis is it's at the end of the interval. Therefore, frametime is always accurate: when it's unusually long, cam just pulled that image.
When it's unusually short, cam pulled that image quickly.

n:       232
mean:    0.0334
min:     0.0250   3.3 sd
max:     0.0480   5.8 sd
sd:      0.0025

So -40% to +40% frame times; high is 100% larger than low
    -> which is significant for bounce projection

But what do they mean? What is the exact information that can be extracted?
What is the order of frametimelogs to the actual picture?

    To do:
    [x] build a deliberate time.sleep() on some frame and compare log to actual frames
    [x] build a frame_start_time log as well; interpret with timelog
    [ ] build a book showing a big frame jump and how that corresponds in frametime


9/14

Found issues with slower than 30 FPS when 1920 and recordOn = True. Multiple options have been added to gui to deal with this:
    codec       - prompt allows
    buffer      - on save frames to memory and only writes to disk 
                  at end-of-record / out of memory
    log type -   simple log (1 col of framerate data) only outputs saved frames data;
                  detailed log (multi col) outputs frames before

    To do:
    [x] add no-loss option to gui


    Notes:
     - can use detailed log, with timelog.py --filtervar recordOn --filterval True
       to debug slow fps
    - if, simple-log with timelog.py --skip 1 --hz is off


Explored compression and loss in books/compare-compression-frames.ipynb:
    png is lossless
    jpg is different encoding from h264
    diff is ~ 25% of pixels ?

    -> we now have strategies for dealing with compression alterations

    Todo:
    [ ] What is time to process each size image?


9/13

guirecord.py is pretty well positioned for it's use. As of yesterday we established frame rate is constant across different different gui options and framesizes. Also record does not delay framerate on laptop cam. (Still to try: logitech and picam)
    
    To remember:
    - use timelog.py to check summary stats on fps data
    - use b_timelog, b_log_vars in guirecord to affect logging behavior

    To do:
    [ ] apply guirecord to logitech and picam (both as streaming and local)

But one thing to notice is that a compressed video frame is smaller and thus less detailed than uncompressed frame. But we do live processing on (in memory) uncompressed frames. So, the live tracking algo could differ in performance from the saved version. We need a way to save uncompressed frames and make them a video.

    To do:
    [x] check that a compressed frame is different than uncompressed
    [x] how to check the size of each in 
    [x] how to save in opencv
    [ ] or do cv2.imsave() of each frame; use ffmpeg to make vid


    Notes:
    b_codec = True can allow a pop-up where you select 
    
    @680
        72  Mb 2sec uncompressed     - output12
        0.5 Mb 2sec h264-compressed  - output11
        but, no slowdown in framerate

    @1920
        400 Mb 2 sec uncompressed     - output13
          7 Mb 2 sec h264-compressed  - output14
        and yes, definetly down possibly 40% in framerate


    Get uncompressed video:
    
        https://stackoverflow.com/questions/15728939/lossless-compression-for-video-in-opencv

        https://docs.opencv.org/trunk/dd/d9e/classcv_1_1VideoWriter.html#ad59c61d8881ba2b2da22cff5487465b5
        
        http://answers.opencv.org/question/3410/saving-video-losslessly-rgb/

        This is the best answer:
        http://answers.opencv.org/question/100967/codecs-list/
            codec=0, fps=0 on vidwriter -> lossless
    
        Questions:
            [ ] does my opencv use "system ffmpeg" or only the ffmpeg.dll on the path in rootdir; and does this matter?
            [ ] how to get the vid's enconding from ffmpeg?
            [ ] Can it be watched though?

        Notes: good discussion how to use ffmpeg to make moveis from photos
        https://stackoverflow.com/questions/24961127/how-to-create-a-video-from-images-with-ffmpeg


9/12


Idea for how to track model perf:

    git-commit  algo-main       y-0     y-1     truth-y0    err-0-y0  time-perframe

    current     long-track-1    99,107  23      100,100     29.9        0.0345
    current     focus-track-2   98,107  19      100,100     9.6         0.651
    09ba        long-track-1
    876c

    y-0 is center, y-0 is radius in a particular picture
    truth-y0 is established by hand - need a contour not a blob here

    record for each git commit, this will track all changes made in other utils as well
    
